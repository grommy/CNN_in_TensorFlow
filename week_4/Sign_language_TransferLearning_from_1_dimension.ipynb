{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sign_language_TransferLearning-from-1-dimension.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grommy/CNN_in_TensorFlow/blob/master/week_4/Sign_language_TransferLearning_from_1_dimension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYtuKeK0dImp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMyh9_mkDHF",
        "colab_type": "text"
      },
      "source": [
        "The data for this exercise is available at: https://www.kaggle.com/datamunge/sign-language-mnist/home\n",
        "\n",
        "Sign up and download to find 2 CSV files: sign_mnist_test.csv and sign_mnist_train.csv -- You will upload both of them using this button before you can continue.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x54LORXJ5oli",
        "colab_type": "code",
        "outputId": "c70d2ce0-1e23-4fe1-8ba1-13064d91aa81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkD5xbhm6Fpf",
        "colab_type": "code",
        "outputId": "7ea1eb5a-7f1e-4d09-b56c-dad8bf98a700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks/CNN_in_TF/Week4/sign-language-mnist"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "american_sign_language.PNG  amer_sign3.png\t sign_mnist_train.csv\n",
            "amer_sign2.png\t\t    sign_mnist_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-9-sGj88ryn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/Colab Notebooks/CNN_in_TF/Week4/sign-language-mnist/sign_mnist_train.csv' .\n",
        "!cp '/content/gdrive/My Drive/Colab Notebooks/CNN_in_TF/Week4/sign-language-mnist/sign_mnist_test.csv' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B40soosz2Vn_",
        "colab_type": "code",
        "outputId": "96d18826-e7a1-4e12-b131-d76c79b8f623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "import pandas as pd\n",
        "X_train = pd.read_csv('sign_mnist_train.csv', nrows=100)\n",
        "X_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>165</td>\n",
              "      <td>159</td>\n",
              "      <td>166</td>\n",
              "      <td>168</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>172</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>169</td>\n",
              "      <td>111</td>\n",
              "      <td>121</td>\n",
              "      <td>129</td>\n",
              "      <td>135</td>\n",
              "      <td>141</td>\n",
              "      <td>144</td>\n",
              "      <td>148</td>\n",
              "      <td>151</td>\n",
              "      <td>154</td>\n",
              "      <td>157</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>205</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>142</td>\n",
              "      <td>151</td>\n",
              "      <td>160</td>\n",
              "      <td>172</td>\n",
              "      <td>196</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>190</td>\n",
              "      <td>135</td>\n",
              "      <td>96</td>\n",
              "      <td>86</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>176</td>\n",
              "      <td>205</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>154</td>\n",
              "      <td>153</td>\n",
              "      <td>152</td>\n",
              "      <td>151</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>148</td>\n",
              "      <td>147</td>\n",
              "      <td>146</td>\n",
              "      <td>144</td>\n",
              "      <td>142</td>\n",
              "      <td>143</td>\n",
              "      <td>138</td>\n",
              "      <td>92</td>\n",
              "      <td>108</td>\n",
              "      <td>158</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>78</td>\n",
              "      <td>120</td>\n",
              "      <td>157</td>\n",
              "      <td>168</td>\n",
              "      <td>107</td>\n",
              "      <td>99</td>\n",
              "      <td>121</td>\n",
              "      <td>133</td>\n",
              "      <td>97</td>\n",
              "      <td>95</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>116</td>\n",
              "      <td>95</td>\n",
              "      <td>79</td>\n",
              "      <td>69</td>\n",
              "      <td>86</td>\n",
              "      <td>139</td>\n",
              "      <td>173</td>\n",
              "      <td>200</td>\n",
              "      <td>185</td>\n",
              "      <td>175</td>\n",
              "      <td>198</td>\n",
              "      <td>124</td>\n",
              "      <td>118</td>\n",
              "      <td>94</td>\n",
              "      <td>140</td>\n",
              "      <td>133</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>178</td>\n",
              "      <td>178</td>\n",
              "      <td>109</td>\n",
              "      <td>52</td>\n",
              "      <td>66</td>\n",
              "      <td>77</td>\n",
              "      <td>83</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>203</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>196</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>193</td>\n",
              "      <td>198</td>\n",
              "      <td>166</td>\n",
              "      <td>132</td>\n",
              "      <td>114</td>\n",
              "      <td>89</td>\n",
              "      <td>74</td>\n",
              "      <td>79</td>\n",
              "      <td>77</td>\n",
              "      <td>74</td>\n",
              "      <td>78</td>\n",
              "      <td>132</td>\n",
              "      <td>188</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>206</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>207</td>\n",
              "      <td>208</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>198</td>\n",
              "      <td>197</td>\n",
              "      <td>195</td>\n",
              "      <td>192</td>\n",
              "      <td>197</td>\n",
              "      <td>171</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>54</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>215</td>\n",
              "      <td>215</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>...</td>\n",
              "      <td>247</td>\n",
              "      <td>242</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>229</td>\n",
              "      <td>227</td>\n",
              "      <td>225</td>\n",
              "      <td>223</td>\n",
              "      <td>221</td>\n",
              "      <td>220</td>\n",
              "      <td>216</td>\n",
              "      <td>58</td>\n",
              "      <td>51</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>159</td>\n",
              "      <td>255</td>\n",
              "      <td>237</td>\n",
              "      <td>239</td>\n",
              "      <td>237</td>\n",
              "      <td>236</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>193</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>192</td>\n",
              "      <td>192</td>\n",
              "      <td>194</td>\n",
              "      <td>194</td>\n",
              "      <td>166</td>\n",
              "      <td>169</td>\n",
              "      <td>172</td>\n",
              "      <td>174</td>\n",
              "      <td>177</td>\n",
              "      <td>180</td>\n",
              "      <td>182</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>77</td>\n",
              "      <td>88</td>\n",
              "      <td>117</td>\n",
              "      <td>123</td>\n",
              "      <td>127</td>\n",
              "      <td>129</td>\n",
              "      <td>134</td>\n",
              "      <td>145</td>\n",
              "      <td>152</td>\n",
              "      <td>156</td>\n",
              "      <td>179</td>\n",
              "      <td>105</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>175</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>152</td>\n",
              "      <td>136</td>\n",
              "      <td>130</td>\n",
              "      <td>136</td>\n",
              "      <td>150</td>\n",
              "      <td>118</td>\n",
              "      <td>92</td>\n",
              "      <td>85</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      3     107     118     127  ...       206       204       203       202\n",
              "1      6     155     157     156  ...       175       103       135       149\n",
              "2      2     187     188     188  ...       198       195       194       195\n",
              "3      2     211     211     212  ...       225       222       229       163\n",
              "4     13     164     167     170  ...       157       163       164       179\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1rlyFO282K8",
        "colab_type": "code",
        "outputId": "244291cf-5859-4b7e-c3c6-13073d4072d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data  sign_mnist_test.csv  sign_mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kxw-_rmcnVu",
        "colab_type": "code",
        "outputId": "d1d4325d-ffe9-4467-e00a-71885c53df88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def get_data(filename):\n",
        "  # You will need to write code that will read the file passed\n",
        "  # into this function. The first line contains the column headers\n",
        "  # so you should ignore it\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\n",
        "  # The first value is the label\n",
        "  # The rest are the pixel values for that picture\n",
        "  # The function will return 2 np.array types. One with all the labels\n",
        "  # One with all the images\n",
        "  #\n",
        "  # Tips: \n",
        "  # If you read a full line (as 'row') then row[0] has the label\n",
        "  # and row[1:785] has the 784 pixel values\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
        "  # You are reading in strings, but need the values to be floats\n",
        "  # Check out np.array().astype for a conversion\n",
        "    images_list = []\n",
        "    labels_list = []    \n",
        "    with open(filename) as training_file:\n",
        "      training_file.readline()\n",
        "      print(\"working with %s\" % filename)\n",
        "      # Your code starts here\n",
        "      for _, line in enumerate(training_file):\n",
        "        row = [int(i) for i in line.split(',')]\n",
        "        labels_list.append(row[0])\n",
        "        images_list.append(row[1:785])\n",
        "        \n",
        "      images = np.reshape(images_list, (-1,28,28))\n",
        "      labels = np.array(labels_list)\n",
        "      \n",
        "      # Your code ends here\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "training_images, training_labels = get_data('sign_mnist_train.csv')\n",
        "testing_images, testing_labels = get_data('sign_mnist_test.csv')\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28)\n",
        "# (27455,)\n",
        "# (7172, 28, 28)\n",
        "# (7172,)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "working with sign_mnist_train.csv\n",
            "working with sign_mnist_test.csv\n",
            "(27455, 28, 28)\n",
            "(27455,)\n",
            "(7172, 28, 28)\n",
            "(7172,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIyNMkiA-7Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images_retyped = training_images.astype('uint8')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gmwagsYTRQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 32\n",
        "img_resized = cv2.resize(training_images_retyped[0], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JiJnlEr-Wvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "imageio.imwrite('first_image.jpg', img_resized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdTW66pc_IVH",
        "colab_type": "code",
        "outputId": "688b9876-e27b-40a8-9391-8fa3f941f50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_image.jpg  gdrive  sample_data  sign_mnist_test.csv  sign_mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVQ2h8XwR2GU",
        "colab_type": "code",
        "outputId": "417623f4-4d03-45b4-af09-64e64b4eacd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_gray = np.expand_dims(training_images[0], 2)\n",
        "img_gray.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVPF5WH9BXBE",
        "colab_type": "code",
        "outputId": "11f2e9c9-f73f-41a0-c6d9-be8416050212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.imshow(training_images[0], cmap='gray');"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnygoJj9RUEx+oqCY/ERBMfmJgvp/EEYCHUSp9mIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv5rl0eC_PNv",
        "colab_type": "code",
        "outputId": "cd9801cc-95d6-4181-9bd5-a2c4832f62f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "image = cv2.imread('first_image.jpg')\n",
        "plt.imshow(image);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFKhJREFUeJzt3V+MXdV1x/Hvwtge/xubwdgM5o+N\nC6pQ1AAaIaqgiCZKRKNIgFQh/IB4QHFUBalI6YNFpUKlPpCqgHioqExBIRXlTwMIVKE2FEVCeSEM\nFMwft40DRrExHoOxx//NmNWHe6yO0d1r7ux7zrkz2b+PZPn67HvuWff4rrlzz7prb3N3RKQ8Zw06\nABEZDCW/SKGU/CKFUvKLFErJL1IoJb9IoZT8IoVS8osUSskvUqiz+9nZzG4AHgIWAP/k7vdF91+y\nZIkPDw+nHiu531lndf8ZFe3TxFhKKj6A6BuUdccRyY3xyy+/TI4tWLAgOZaKv+1vlM6VONqyb98+\nJicne3rxZCe/mS0A/gH4DrALeN3MXnT391P7DA8Ps2nTpq5jixYtSh5raGio6/bFixcn91m4cGFy\n7Oyz0087Gku92KM4Tp48mRyLYoweMycho/M7NTWVHDt69Ghy7Jxzzpl1HNH5iH5ARaLzkTrHucnf\nxA+NOh9zy5YtPd+3n1/7rwF2uPsH7n4SeAq4sY/HE5EW9ZP864DfTfv3rmqbiMwDjV/wM7PNZjZu\nZuPHjh1r+nAi0qN+kn83cNG0f19YbTuDu2919zF3H1uyZEkfhxOROvWT/K8Dl5nZBjNbBNwKvFhP\nWCLStOyr/e4+ZWZ3Av9Bp9T3mLu/N9N+dZewctQdQ+7V2tw46r7iHMWxd+/erMdcvnz5rPfJKR22\nLYqj7tdB0+XIvur87v4S8FJNsYhIi/QNP5FCKflFCqXkFymUkl+kUEp+kUL1dbV/tsws2bwRNXXU\nuc/pOOocy+3cy21kySkB5T7niYmJ5Fj0pa1UY1LUYJRb6osae1JjTZz7uku3TZc39c4vUiglv0ih\nlPwihVLyixRKyS9SqFav9kO9V+7bnsOv7vn9cq84R3JijK6WnzhxIjkWXflOXbmPrujnno+c55zb\noNNEM9agmpb0zi9SKCW/SKGU/CKFUvKLFErJL1IoJb9IoeZ1qW+uNPbklmpy44ieW1RKS4lW0YnK\ngFGMOXFEx2ri/7POfdpWx/x+eucXKZSSX6RQSn6RQin5RQql5BcplJJfpFB9lfrMbCdwCDgFTLn7\n2Az3zyrbpUovTZR/6o4jt5srGjv77PR/28KFC7tuP3XqVHKfaPXkqamp5FgkZ77DKMa6/8+aUHfn\nXs7jzeY4ddT5/8TdP63hcUSkRfq1X6RQ/Sa/A78wszfMbHMdAYlIO/r9tf86d99tZmuAl83sv939\n1el3qH4obAYYHh7u83AiUpe+3vndfXf19wTwPHBNl/tsdfcxdx9bunRpP4cTkRplJ7+ZLTOzFadv\nA98F3q0rMBFpVj+/9q8Fnq9KC2cD/+Lu/z7TTnN9As9ITqkv6lTLLQ1FHXOpMuAXX3yR3Of48ePJ\nsUhOHHNlIsu5NBHnoJbryk5+d/8A+HqNsYhIi1TqEymUkl+kUEp+kUIp+UUKpeQXKVTrE3jmyOlg\nmivr8dUx0eJX5ax3F8URTeAZdRAuWrQoObZ48eKu26POvdzJQqP9UmPR84rkrvGX85hNvHam0zu/\nSKGU/CKFUvKLFErJL1IoJb9IoVq92m9mySvVOVew277anxqLmmaGhoaSY6n59mZ6zOgqcOoKfDRP\n34cffpgci+ZgWLlyZXIsVUFIVQEgPvcnTpxIjq1YsSI5lnreUYWmCdH/WWosZ5/Z0Du/SKGU/CKF\nUvKLFErJL1IoJb9IoZT8IoWaF409KXOl1BeV7CJRuSZnTkNIxxiVHM8999zkWNQAE5UjUw01UexL\nlixJjkWl4Jx5EtucLzCXGntEpBFKfpFCKflFCqXkFymUkl+kUEp+kULNWOozs8eA7wMT7v61atsI\n8DSwHtgJ3OLun/dywDo79OZDqS93ua6otBWNpWKMFkldu3Ztcixayuvw4cPJsdRzi87VsmXLkmNR\niXBqaio5ljNXX9tLeQ2qHNnLO/9PgRu+sm0L8Iq7Xwa8Uv1bROaRGZPf3V8F9n9l843A49Xtx4Gb\nao5LRBqW+5l/rbvvqW5/QmfFXhGZR/q+4OedDyzJDztmttnMxs1s/OjRo/0eTkRqkpv8e81sFKD6\neyJ1R3ff6u5j7j4WXXQSkXblJv+LwO3V7duBF+oJR0Ta0kup70ngemC1me0C7gHuA54xszuAj4Bb\nej1gqnyR08VWd+db7ljuUlJRGSqa6DIq9aXKRtE+0QSYBw4cSI5Fpb7UOYmeV9TVF03gGYmeW91y\nl/JKvVaj104dZkx+d9+UGPp2zbGISIv0DT+RQin5RQql5BcplJJfpFBKfpFCtb5WX51lu9ySXW6J\nMGd9tyiOqPyWWnNvpsdMlYdSa+fNNPbZZ58lx6L1/1Jf6IpKb1HHX1Tqi87H8uXLu25ve62+HFGM\ndXQCzv0zICKNUPKLFErJL1IoJb9IoZT8IoVS8osUqvW1+uqcjLOJkl3dJceofBWV83I69yC9ft6R\nI0eS+0TlvGgCz2gsVeqL1veLugSjUl/U/ZaanDTqICyF3vlFCqXkFymUkl+kUEp+kUIp+UUKNa+v\n9s+V5bqiq/ZR9SCazy6KI1qe6tSpU123R1f7P/3001k/3kxjKVGFIHe/qMFoZGSk6/aLL744K47f\nJ3rnFymUkl+kUEp+kUIp+UUKpeQXKZSSX6RQvSzX9RjwfWDC3b9WbbsX+AGwr7rb3e7+Ui8HnAul\nvrrlNuhEy3VFZbSokSVnDr/chpqcpp+o9Bk9XrTC8+TkZHIsNYdfVOrLfe1EDVe5S3k1qZd3/p8C\nN3TZ/qC7X1n96SnxRWTumDH53f1VYH8LsYhIi/r5zH+nmW0zs8fM7JzaIhKRVuQm/8PARuBKYA9w\nf+qOZrbZzMbNbDz6iqmItCsr+d19r7ufcvcvgUeAa4L7bnX3MXcfW7ZsWW6cIlKzrOQ3s9Fp/7wZ\neLeecESkLb2U+p4ErgdWm9ku4B7gejO7EnBgJ/DDBmNMloeiUlnuPH1Rp11q3rdVq1Yl94lijLrp\nPv744+RYNA9eqtQXdb6Njo4mx3bs2JEci7oL9+7d23V7dD5WrlyZHIvmQoxKZfv3d79WHZVSc5dY\ny10CLHW8qKRbx3JdMya/u2/qsvnRno8gInOSvuEnUiglv0ihlPwihVLyixRKyS9SqFYn8DSz1rrt\n2uzqyyk1AezatStr7MCBA8mxVEkvKmGuWbMmORZ1LEZlu1Q3YNQlGH0JLNWdB3kTiUavj7pLdrma\nfg3rnV+kUEp+kUIp+UUKpeQXKZSSX6RQSn6RQrW+Vl9K3RN4timK4+DBg8mxPXv2JMd2796dHIs6\n/j7//POu2y+88MLkPrnr1kVdZ6nOw9yJSaOSY3T+ly5d2nV71J3XxDqPOVTqE5FGKPlFCqXkFymU\nkl+kUEp+kUK1frU/1TTR5nJduVdR6646RA1B0ZXvaOmt1JJX0bx/UfzRdOvRvICpx0zNgwhxo1A0\nX2A0v9/atWu7bo+u9kfarDBFDUZ1LPGld36RQin5RQql5BcplJJfpFBKfpFCKflFCtXLcl0XAT8D\n1tJZnmuruz9kZiPA08B6Okt23eLu3btKzny8rtujskbdpb5Izn5RGSqaO2/FihXJsWg+u2i/VBkw\nKg1NTEwkx44ePZoci553aumt6HlFr4HJycnk2PDwcHJs9erVXbfnlvpy5ZTmotdiHct19fLOPwX8\n2N2vAK4FfmRmVwBbgFfc/TLglerfIjJPzJj87r7H3d+sbh8CtgPrgBuBx6u7PQ7c1FSQIlK/WX3m\nN7P1wFXAa8Badz/dkP4JnY8FIjJP9Jz8ZrYceBa4y93P+ADmnQ8gXT+EmNlmMxs3s/Hoq6Ii0q6e\nkt/MFtJJ/Cfc/blq814zG63GR4GuV43cfau7j7n7WHSxR0TaNWPyW+fy4aPAdnd/YNrQi8Dt1e3b\ngRfqD09EmtJLV983gNuAd8zsrWrb3cB9wDNmdgfwEXDLTA9kZq119c0UR52iJaii8lXU4Zaaew7i\npatSpbkoxmguwaGhoeRYVMYcGRnpuj3qwIs6D6OxqGyXOle5pb6oZJfbaZd6PUaPV8dreMbkd/df\nAakjfbvvCERkIPQNP5FCKflFCqXkFymUkl+kUEp+kULN6+W6ch+vblFJJlqeKhKV0XImwYwmBI3O\nVWoCTIjLdqlS5aFDh5L7ROcx1SUIcP755yfHUh1/UQk2Ep3HujX9utc7v0ihlPwihVLyixRKyS9S\nKCW/SKGU/CKFar3UV2cJrs1yXnS8qEMsKg1Fpa1FixYlx6IyYKr8Fp2rVAcewKpVq5JjUckx5eDB\ng8mxqHR4wQUXJMfWrVuXHEtNdhp1CUaaeM3Vse5eDr3zixRKyS9SKCW/SKGU/CKFUvKLFKrVq/3u\nnrz6HTXA5DRTRFfLc5s6jh07Nutj5TaCRHPuRUtopSoPUYzHjx9PjkVXxaPZmFNX9aPnFTURXXzx\nxcmx6Gp/HctaTRe9duqe36/pKoDe+UUKpeQXKZSSX6RQSn6RQin5RQql5Bcp1IylPjO7CPgZnSW4\nHdjq7g+Z2b3AD4B91V3vdveXcgOJSig5ZZncElsUR2osKodFZbRoLIo/auxJld9Sc/tB3FAT2b9/\nf3IsNVdf1AwUlfqiJcpyRK+pppfJ6vV4uTH2qpc6/xTwY3d/08xWAG+Y2cvV2IPu/vd9RyEiretl\nrb49wJ7q9iEz2w6kv1UhIvPCrD7zm9l64CrgtWrTnWa2zcweM7Nzao5NRBrUc/Kb2XLgWeAud58E\nHgY2AlfS+c3g/sR+m81s3MzGjxw5UkPIIlKHnpLfzBbSSfwn3P05AHff6+6n3P1L4BHgmm77uvtW\ndx9z97Hou+Ai0q4Zk986lxwfBba7+wPTto9Ou9vNwLv1hyciTenlav83gNuAd8zsrWrb3cAmM7uS\nTvlvJ/DDmR7IzJLli6jEFs2RlxKVynLKeU3EEXUyRnFEpb6pqala44jKkVF3YSqOqDvvkksuSY6l\nlt2Cub+cWxPqiL+Xq/2/ArodKbumLyKDp2/4iRRKyS9SKCW/SKGU/CKFUvKLFKr15bpSojJa7oSb\nKVGZJIojp9SXe6yoCy96zFSJLZo4M3cs6tA777zzum6PynmrV69Ojg0NDSXHoq7K1GsnKn020fGX\nM7lnTufebEqAeucXKZSSX6RQSn6RQin5RQql5BcplJJfpFCtl/pyuvpySn3RPtG6ddFklqnYJycn\nk/uk1vcDOHnyZNZYVH5LHS/aJzpXUUns0ksvTY5dfvnlXbdH5byoWzFSd3k2Uvd6fJB+XWmtPhFp\nhJJfpFBKfpFCKflFCqXkFymUkl+kUHOmqy9HVKKKSnZRh1hUGkp1zKXWpQM4ePBg1tjhw4ezxlIl\nvahkFz3nkZGR5Nj69euTYxs3bpz1saIYo7JXzjqPuRNg1t25F401vVaf3vlFCqXkFymUkl+kUEp+\nkUIp+UUKNePVfjMbAl4FFlf3/7m732NmG4CngHOBN4Db3D3djfL/j9dfxD0+VtS8E13tjx4ztazV\n0qVLk/scOHAgORY1/UQVhGgJrdQV8+h5RVfLUw06AKOjo8mx1Px+0dJgua+NnCvp0XNuuqFmrujl\nnf8E8C13/zqd5bhvMLNrgZ8AD7r7HwCfA3c0F6aI1G3G5PeO04XlhdUfB74F/Lza/jhwUyMRikgj\nevrMb2YLqhV6J4CXgd8CB9z99LdedgHrmglRRJrQU/K7+yl3vxK4ELgG+MNeD2Bmm81s3MzGjxw5\nkhmmiNRtVlf73f0A8Evgj4FVZnb6guGFwO7EPlvdfczdx5YtW9ZXsCJSnxmT38zOM7NV1e0lwHeA\n7XR+CPxZdbfbgReaClJE6tdLY88o8LiZLaDzw+IZd/83M3sfeMrM/hb4L+DRpoLMaXyIGkiipp+c\nMs+aNWuSY1HzTiTVRARxuSxH1FCzYcOG5Fj0m1w0B2FK7v9LdK5yXjtNLNeVI+dYs4lhxuR3923A\nVV22f0Dn87+IzEP6hp9IoZT8IoVS8osUSskvUiglv0ihrM0OJjPbB3xU/XM18GlrB09THGdSHGea\nb3Fc4u7n9fKArSb/GQc2G3f3sYEcXHEoDsWhX/tFSqXkFynUIJN/6wCPPZ3iOJPiONPvbRwD+8wv\nIoOlX/tFCjWQ5DezG8zsf8xsh5ltGUQMVRw7zewdM3vLzMZbPO5jZjZhZu9O2zZiZi+b2W+qv88Z\nUBz3mtnu6py8ZWbfayGOi8zsl2b2vpm9Z2Z/UW1v9ZwEcbR6TsxsyMx+bWZvV3H8TbV9g5m9VuXN\n02aWnqW2F+7e6h9gAZ1pwC4FFgFvA1e0HUcVy05g9QCO+03gauDdadv+DthS3d4C/GRAcdwL/GXL\n52MUuLq6vQL4X+CKts9JEEer5wQwYHl1eyHwGnAt8Axwa7X9H4E/7+c4g3jnvwbY4e4feGeq76eA\nGwcQx8C4+6vA/q9svpHORKjQ0oSoiTha5+573P3N6vYhOpPFrKPlcxLE0SrvaHzS3EEk/zrgd9P+\nPcjJPx34hZm9YWabBxTDaWvdfU91+xNg7QBjudPMtlUfCxr/+DGdma2nM3/EawzwnHwlDmj5nLQx\naW7pF/yuc/ergT8FfmRm3xx0QND5yU/nB9MgPAxspLNGwx7g/rYObGbLgWeBu9x9cvpYm+ekSxyt\nnxPvY9LcXg0i+XcDF037d3Lyz6a5++7q7wngeQY7M9FeMxsFqP6eGEQQ7r63euF9CTxCS+fEzBbS\nSbgn3P25anPr56RbHIM6J9WxZz1pbq8GkfyvA5dVVy4XAbcCL7YdhJktM7MVp28D3wXejfdq1It0\nJkKFAU6IejrZKjfTwjmxzsRzjwLb3f2BaUOtnpNUHG2fk9YmzW3rCuZXrmZ+j86V1N8CfzWgGC6l\nU2l4G3ivzTiAJ+n8+vgFnc9ud9BZ8/AV4DfAfwIjA4rjn4F3gG10km+0hTiuo/Mr/TbgrerP99o+\nJ0EcrZ4T4I/oTIq7jc4Pmr+e9pr9NbAD+FdgcT/H0Tf8RApV+gU/kWIp+UUKpeQXKZSSX6RQSn6R\nQin5RQql5BcplJJfpFD/B97LoVgFw0pcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "205STce-AqIk",
        "colab_type": "code",
        "outputId": "f188ac40-0529-47ff-e356-218e91581f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "image_clr = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_clr);"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQin5RQql5BcplJJfpFD/B97LoVgFw0pcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eG7AEErBBxK",
        "colab_type": "code",
        "outputId": "1dc01c7a-7ae3-49b2-f147-fa25c493629e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(training_images[0].shape)\n",
        "print(image.shape)\n",
        "print(image_clr.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy-cXhx-8GTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b5f19e67-3919-4226-eddf-f54a52f59f0f"
      },
      "source": [
        "def gray_img_reshape(image_arr_2d, target_size):\n",
        "  # large image is shape (1, 128, 128)\n",
        "  # small image is shape (1, 64, 64)\n",
        "  new_arr = []\n",
        "  image_arr = image_arr_2d.astype('float32')\n",
        "  for img in image_arr:\n",
        "    new_image = cv2.resize(img, (target_size,target_size))\n",
        "    new_arr.append(new_image)\n",
        "\n",
        "  return np.array(new_arr)\n",
        "\n",
        "sm = gray_img_reshape(training_images[:5], target_size=75)\n",
        "print(sm.shape)\n",
        "plt.imshow(sm[0], cmap='gray');"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 75, 75)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRgg/w+AM8SHHe/KgQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z0DjPJWDW5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 75\n",
        "\n",
        "training_images_resized = gray_img_reshape(training_images, target_size=IMG_SIZE)\n",
        "testing_images_resized = gray_img_reshape(testing_images, target_size=IMG_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHc5n0dLXKHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68853b37-b495-4830-b9c7-426e2de4b107"
      },
      "source": [
        "# In this section you will have to add another dimension to the data\n",
        "# So, for example, if your array is (10000, 28, 28)\n",
        "# You will need to make it (10000, 28, 28, 1)\n",
        "# Hint: np.expand_dims\n",
        "\n",
        "training_images_ex = np.expand_dims(training_images_resized, axis=3)\n",
        "testing_images_ex = np.expand_dims(testing_images_resized, axis=3)\n",
        "\n",
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "    \n",
        "# Keep These\n",
        "print(training_images_ex.shape)\n",
        "print(testing_images_ex.shape)\n",
        "    \n",
        "# Their output should be:\n",
        "# (27455, 28, 28, 1)\n",
        "# (7172, 28, 28, 1)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27455, 75, 75, 1)\n",
            "(7172, 75, 75, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNDf0HwOqrVO",
        "colab_type": "code",
        "outputId": "d2028d50-d1a6-42f0-f898-92b32ff9e77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "NUM_CLASSES = len(np.unique(training_labels)) + 1\n",
        "print(NUM_CLASSES)\n",
        "\n",
        "training_labels_cat = tf.keras.utils.to_categorical(training_labels, dtype='int')\n",
        "testing_labels_cat = tf.keras.utils.to_categorical(testing_labels, dtype='int')\n",
        "print(training_labels_cat[0])\n",
        "print(testing_labels_cat[0])\n",
        "print(training_labels_cat.shape)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(27455, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se5dj8WeXySW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BS = 64\n",
        "train_data_bw_iterator = train_datagen.flow(training_images_ex, training_labels_cat, batch_size=BS)\n",
        "validation_data_bw_iterator = validation_datagen.flow(testing_images_ex, testing_labels_cat, batch_size=BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrqfFSyziW5T",
        "colab_type": "text"
      },
      "source": [
        "## Use Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WebdzbtzSPku",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751 <br>\n",
        "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lvrEzGGIU4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXYBeglnLXU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget --no-check-certificate \\\n",
        "#     https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "#     -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd2qhrKKIz8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = InceptionV3(input_shape = (75, 75, 3), \n",
        "                                include_top = False, \n",
        "                                weights = \"imagenet\")\n",
        "# local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "# pre_trained_model.load_weights(\"imagenet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wikhVDdKAwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.applications import ResNet50\n",
        "# pre_trained_model = ResNet50(input_shape = (28, 28, 1), \n",
        "#                                 include_top = False, \n",
        "#                                 weights = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsUGNoiMPYtS",
        "colab_type": "code",
        "outputId": "bd3eb575-af99-462a-b9fa-1294fa63f8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pre_trained_model.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 37, 37, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 37, 37, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 37, 37, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 35, 35, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 35, 35, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 35, 35, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 35, 35, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 35, 35, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 35, 35, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 17, 17, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 17, 17, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 17, 17, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 17, 17, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 15, 15, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 15, 15, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 15, 15, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 7, 7, 64)     12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 7, 7, 64)     192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 7, 7, 64)     0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 7, 7, 48)     9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 7, 7, 96)     55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 7, 7, 48)     144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 7, 7, 96)     288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 7, 7, 48)     0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 7, 7, 96)     0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 7, 7, 192)    0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 7, 7, 64)     12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 7, 7, 64)     76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 7, 7, 96)     82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 7, 7, 32)     6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 7, 7, 64)     192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 7, 7, 64)     192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 7, 7, 96)     288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 7, 7, 32)     96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 7, 7, 64)     0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 7, 7, 64)     0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 7, 7, 96)     0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 7, 7, 32)     0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 7, 7, 64)     192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 7, 7, 64)     0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 7, 7, 96)     55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 7, 7, 48)     144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 7, 7, 96)     288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 7, 7, 48)     0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 7, 7, 96)     0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 7, 7, 64)     76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 7, 7, 96)     82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 7, 7, 64)     16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 7, 7, 64)     192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 7, 7, 64)     192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 7, 7, 96)     288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 7, 7, 64)     192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 7, 7, 64)     0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 7, 7, 64)     0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 7, 7, 96)     0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 7, 7, 64)     0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 7, 7, 64)     192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 7, 7, 64)     0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 7, 7, 96)     55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 7, 7, 48)     144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 7, 7, 96)     288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 7, 7, 48)     0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 7, 7, 96)     0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 7, 7, 64)     76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 7, 7, 96)     82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 7, 7, 64)     18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 7, 7, 64)     192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 7, 7, 64)     192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 7, 7, 96)     288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 7, 7, 64)     192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 7, 7, 64)     0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 7, 7, 64)     0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 7, 7, 96)     0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 7, 7, 64)     0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 7, 7, 64)     192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 7, 7, 64)     0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 7, 7, 96)     55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 7, 7, 96)     288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 7, 7, 96)     0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 3, 3, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 3, 3, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 3, 3, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 3, 3, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 3, 3, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 3, 3, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 3, 3, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 3, 3, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 3, 3, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 3, 3, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 3, 3, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 3, 3, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 3, 3, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 3, 3, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 3, 3, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 3, 3, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 3, 3, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 3, 3, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 3, 3, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 3, 3, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 3, 3, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 3, 3, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 3, 3, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 3, 3, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 3, 3, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 3, 3, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 3, 3, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 3, 3, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 3, 3, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 3, 3, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 3, 3, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 3, 3, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 3, 3, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 3, 3, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 3, 3, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 3, 3, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 3, 3, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 3, 3, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 3, 3, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 3, 3, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 3, 3, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 3, 3, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 3, 3, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 3, 3, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 3, 3, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 3, 3, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 3, 3, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 3, 3, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 3, 3, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 3, 3, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 3, 3, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 3, 3, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 3, 3, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 3, 3, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 3, 3, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 3, 3, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 3, 3, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 3, 3, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 3, 3, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 3, 3, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 3, 3, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 3, 3, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 3, 3, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 3, 3, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 3, 3, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 3, 3, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 3, 3, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 3, 3, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 3, 3, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 3, 3, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 3, 3, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 3, 3, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 3, 3, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 3, 3, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 3, 3, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 3, 3, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 3, 3, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 3, 3, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 3, 3, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 3, 3, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 3, 3, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 3, 3, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 3, 3, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 3, 3, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 3, 3, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 3, 3, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 3, 3, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 3, 3, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 3, 3, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 3, 3, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 3, 3, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 3, 3, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 3, 3, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 3, 3, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 3, 3, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 3, 3, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 3, 3, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 3, 3, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 3, 3, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 3, 3, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 3, 3, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 3, 3, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 3, 3, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 3, 3, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 3, 3, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 3, 3, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 3, 3, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 3, 3, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 3, 3, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 3, 3, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 3, 3, 192)    576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 3, 3, 192)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 3, 3, 192)    258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 3, 3, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 3, 3, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 3, 3, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 3, 3, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 3, 3, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 3, 3, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 3, 3, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 1, 1, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 1, 1, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 1, 1, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 1, 1, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 1, 1, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 1, 1, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 1, 1, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 1, 1, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 1, 1, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 1, 1, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 1, 1, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 1, 1, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 1, 1, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 1, 1, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 1, 1, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 1, 1, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 1, 1, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 1, 1, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 1, 1, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 1, 1, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 1, 1, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 1, 1, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 1, 1, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 1, 1, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 1, 1, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 1, 1, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 1, 1, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 1, 1, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 1, 1, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 1, 1, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 1, 1, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 1, 1, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 1, 1, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 1, 1, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 1, 1, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 1, 1, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 1, 1, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 1, 1, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 1, 1, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 1, 1, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 1, 1, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 1, 1, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 1, 1, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 1, 1, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 1, 1, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 1, 1, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 1, 1, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 1, 1, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 1, 1, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 1, 1, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 1, 1, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 1, 1, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 1, 1, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1, 1, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 1, 1, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUytrOjraFb0",
        "colab_type": "text"
      },
      "source": [
        "## TO RGB on the Fly\n",
        "\n",
        "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/63710 <br>\n",
        "https://forums.fast.ai/t/black-and-white-images-on-vgg16/2479/12 <br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "img_input = Input(shape=(img_size_target,img_size_target,1))\n",
        "img_conc = Concatenate()([img_input, img_input, img_input])    \n",
        "\n",
        "model = Unet(backbone_name='resnet34', input_tensor=img_conc, encoder_weights='imagenet', freeze_encoder=True)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgJjbZAKizJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, \\\n",
        "  GlobalAveragePooling2D, Conv2D, MaxPooling2D, Input, Concatenate\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "def build_tl_model(original_model, num_classes, num_layer_to_drop=0, save_file=None):\n",
        "  \"\"\"\n",
        "  Perform 'surgery' on a pretrained model. Then add layers to create a new model\n",
        "  that has just one final, trainable layer with softmax activation for \n",
        "  multi-class output.\n",
        "  \"\"\"\n",
        "  img_input = Input(shape=(IMG_SIZE, IMG_SIZE, 1, ))\n",
        "  img_conc = Concatenate(axis=-1)([img_input, img_input, img_input])\n",
        "  input_model = Model(inputs=img_input, outputs=img_conc, name=\"input_model\")\n",
        "  \n",
        "  # ______________________________________________________________________________\n",
        "  # Extract needed info from pre-trained model.\n",
        "  bottleneck_input  = original_model.get_layer(index=0).input\n",
        "  bottleneck_output = original_model.get_layer('mixed5').output\n",
        "  bottleneck_model = Model(inputs=bottleneck_input, outputs=bottleneck_output,\n",
        "                          name=\"bottleneck\")\n",
        "\n",
        "  # ______________________________________________________________________________\n",
        "  # Freeze these layers so we are not retraining the full model. \n",
        "  for layer in bottleneck_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # ______________________________________________________________________________\n",
        "  # Build new transfer learning model.\n",
        "  new_model = Sequential()\n",
        "  new_model.add(input_model)\n",
        "  new_model.add(bottleneck_model)\n",
        "#   new_model.add(Conv2D(36, kernel_size=(3,3), activation='relu'))\n",
        "  new_model.add(GlobalAveragePooling2D())\n",
        "  new_model.add(Dense(128, activation=\"relu\"))\n",
        "  new_model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "#   NUM_CLASSES = len(os.listdir(IMG_DIR))  # How many image classes are in our new data?\n",
        "  BOTTLENECK_DIM = bottleneck_output.shape.dims[1]  # The number of nodes in the second to last layer of the pre-trained model.\n",
        "  print(BOTTLENECK_DIM)                    \n",
        "\n",
        "  if save_file:\n",
        "    new_model.save(save_file)\n",
        "\n",
        "  return new_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqjsiLpCndD7",
        "colab_type": "code",
        "outputId": "52352ed4-6aef-4ce3-e82b-6ac9bd6fa25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "transfer_model = build_tl_model(pre_trained_model, num_classes=NUM_CLASSES)\n",
        "transfer_model.summary()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_model (Model)          (None, 75, 75, 3)         0         \n",
            "_________________________________________________________________\n",
            "bottleneck (Model)           (None, 3, 3, 768)         5138656   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_6 ( (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               98432     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 25)                3225      \n",
            "=================================================================\n",
            "Total params: 5,240,313\n",
            "Trainable params: 101,657\n",
            "Non-trainable params: 5,138,656\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1oELXbndNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model. \n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "transfer_model.compile(optimizer=RMSprop(lr=1e-2), loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiX7-NMdwblJ",
        "colab": {}
      },
      "source": [
        "# # Compile Model. \n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# transfer_model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nujki8g1ndWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "transfer_checkpoint = ModelCheckpoint(filepath='transfer_model_1dim.h5',\n",
        "                             monitor='val_acc', \n",
        "                             save_best_only=True, \n",
        "                             load_weights_on_restart=True,\n",
        "                            )\n",
        "transfer_earlystopping = EarlyStopping(monitor='val_acc',\n",
        "                             patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isnGTupJt_6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BS = 64\n",
        "train_data_bw_iterator = train_datagen.flow(training_images_ex, training_labels_cat, batch_size=BS)\n",
        "validation_data_bw_iterator = validation_datagen.flow(testing_images_ex, testing_labels_cat, batch_size=BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXLwUc4_tjVY",
        "colab_type": "code",
        "outputId": "78294299-289d-4c27-83f3-4c78563ff4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Train the Model\n",
        "EPOCHS = 20\n",
        "\n",
        "transfer_history = transfer_model.fit_generator(\n",
        "     train_data_bw_iterator,\n",
        "\t   validation_data=validation_data_bw_iterator,\n",
        "\t   steps_per_epoch=len(training_images) // BS,\n",
        "     epochs=EPOCHS,\n",
        "     callbacks=[transfer_checkpoint, transfer_earlystopping]\n",
        ")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "428/428 [==============================] - 301s 703ms/step - loss: 1.2914 - acc: 0.5853 - val_loss: 3.8471 - val_acc: 0.2974\n",
            "Epoch 2/20\n",
            "428/428 [==============================] - 293s 684ms/step - loss: 0.7179 - acc: 0.7571 - val_loss: 3.3151 - val_acc: 0.3961\n",
            "Epoch 3/20\n",
            "428/428 [==============================] - 296s 691ms/step - loss: 0.6369 - acc: 0.7888 - val_loss: 4.5461 - val_acc: 0.3652\n",
            "Epoch 4/20\n",
            "428/428 [==============================] - 295s 688ms/step - loss: 0.5893 - acc: 0.8057 - val_loss: 7.2947 - val_acc: 0.2734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oS3duzLt3Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjVIlMRgx4eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}