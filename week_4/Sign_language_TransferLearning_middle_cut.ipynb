{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sign_language_TransferLearning-middle-cut.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grommy/CNN_in_TensorFlow/blob/master/week_4/Sign_language_TransferLearning_middle_cut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYtuKeK0dImp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMyh9_mkDHF",
        "colab_type": "text"
      },
      "source": [
        "The data for this exercise is available at: https://www.kaggle.com/datamunge/sign-language-mnist/home\n",
        "\n",
        "Sign up and download to find 2 CSV files: sign_mnist_test.csv and sign_mnist_train.csv -- You will upload both of them using this button before you can continue.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x54LORXJ5oli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fa142a57-62d9-42e8-faf8-e2965472bb61"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkD5xbhm6Fpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b894827-dd57-4413-91ac-f07cbe04a605"
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks/CNN_in_TF/Week4/sign-language-mnist"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "american_sign_language.PNG  amer_sign3.png\t sign_mnist_train.csv\n",
            "amer_sign2.png\t\t    sign_mnist_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-9-sGj88ryn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/Colab Notebooks/CNN_in_TF/Week4/sign-language-mnist/sign_mnist_train.csv' .\n",
        "!cp '/content/gdrive/My Drive/Colab Notebooks/CNN_in_TF/Week4/sign-language-mnist/sign_mnist_test.csv' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B40soosz2Vn_",
        "colab_type": "code",
        "outputId": "ddc0483b-d411-4df4-f3ef-a8e765e810a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "import pandas as pd\n",
        "X_train = pd.read_csv('sign_mnist_train.csv', nrows=100)\n",
        "X_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>165</td>\n",
              "      <td>159</td>\n",
              "      <td>166</td>\n",
              "      <td>168</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>172</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>169</td>\n",
              "      <td>111</td>\n",
              "      <td>121</td>\n",
              "      <td>129</td>\n",
              "      <td>135</td>\n",
              "      <td>141</td>\n",
              "      <td>144</td>\n",
              "      <td>148</td>\n",
              "      <td>151</td>\n",
              "      <td>154</td>\n",
              "      <td>157</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>205</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>142</td>\n",
              "      <td>151</td>\n",
              "      <td>160</td>\n",
              "      <td>172</td>\n",
              "      <td>196</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>190</td>\n",
              "      <td>135</td>\n",
              "      <td>96</td>\n",
              "      <td>86</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>176</td>\n",
              "      <td>205</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>154</td>\n",
              "      <td>153</td>\n",
              "      <td>152</td>\n",
              "      <td>151</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>148</td>\n",
              "      <td>147</td>\n",
              "      <td>146</td>\n",
              "      <td>144</td>\n",
              "      <td>142</td>\n",
              "      <td>143</td>\n",
              "      <td>138</td>\n",
              "      <td>92</td>\n",
              "      <td>108</td>\n",
              "      <td>158</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>78</td>\n",
              "      <td>120</td>\n",
              "      <td>157</td>\n",
              "      <td>168</td>\n",
              "      <td>107</td>\n",
              "      <td>99</td>\n",
              "      <td>121</td>\n",
              "      <td>133</td>\n",
              "      <td>97</td>\n",
              "      <td>95</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>116</td>\n",
              "      <td>95</td>\n",
              "      <td>79</td>\n",
              "      <td>69</td>\n",
              "      <td>86</td>\n",
              "      <td>139</td>\n",
              "      <td>173</td>\n",
              "      <td>200</td>\n",
              "      <td>185</td>\n",
              "      <td>175</td>\n",
              "      <td>198</td>\n",
              "      <td>124</td>\n",
              "      <td>118</td>\n",
              "      <td>94</td>\n",
              "      <td>140</td>\n",
              "      <td>133</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>178</td>\n",
              "      <td>178</td>\n",
              "      <td>109</td>\n",
              "      <td>52</td>\n",
              "      <td>66</td>\n",
              "      <td>77</td>\n",
              "      <td>83</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>203</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>196</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>193</td>\n",
              "      <td>198</td>\n",
              "      <td>166</td>\n",
              "      <td>132</td>\n",
              "      <td>114</td>\n",
              "      <td>89</td>\n",
              "      <td>74</td>\n",
              "      <td>79</td>\n",
              "      <td>77</td>\n",
              "      <td>74</td>\n",
              "      <td>78</td>\n",
              "      <td>132</td>\n",
              "      <td>188</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>206</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>207</td>\n",
              "      <td>208</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>198</td>\n",
              "      <td>197</td>\n",
              "      <td>195</td>\n",
              "      <td>192</td>\n",
              "      <td>197</td>\n",
              "      <td>171</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>54</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>215</td>\n",
              "      <td>215</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>...</td>\n",
              "      <td>247</td>\n",
              "      <td>242</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>229</td>\n",
              "      <td>227</td>\n",
              "      <td>225</td>\n",
              "      <td>223</td>\n",
              "      <td>221</td>\n",
              "      <td>220</td>\n",
              "      <td>216</td>\n",
              "      <td>58</td>\n",
              "      <td>51</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>159</td>\n",
              "      <td>255</td>\n",
              "      <td>237</td>\n",
              "      <td>239</td>\n",
              "      <td>237</td>\n",
              "      <td>236</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>193</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>192</td>\n",
              "      <td>192</td>\n",
              "      <td>194</td>\n",
              "      <td>194</td>\n",
              "      <td>166</td>\n",
              "      <td>169</td>\n",
              "      <td>172</td>\n",
              "      <td>174</td>\n",
              "      <td>177</td>\n",
              "      <td>180</td>\n",
              "      <td>182</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>77</td>\n",
              "      <td>88</td>\n",
              "      <td>117</td>\n",
              "      <td>123</td>\n",
              "      <td>127</td>\n",
              "      <td>129</td>\n",
              "      <td>134</td>\n",
              "      <td>145</td>\n",
              "      <td>152</td>\n",
              "      <td>156</td>\n",
              "      <td>179</td>\n",
              "      <td>105</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>175</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>152</td>\n",
              "      <td>136</td>\n",
              "      <td>130</td>\n",
              "      <td>136</td>\n",
              "      <td>150</td>\n",
              "      <td>118</td>\n",
              "      <td>92</td>\n",
              "      <td>85</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      3     107     118     127  ...       206       204       203       202\n",
              "1      6     155     157     156  ...       175       103       135       149\n",
              "2      2     187     188     188  ...       198       195       194       195\n",
              "3      2     211     211     212  ...       225       222       229       163\n",
              "4     13     164     167     170  ...       157       163       164       179\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1rlyFO282K8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b09e47a5-8717-4deb-8d90-13ce1b006c65"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data  sign_mnist_test.csv  sign_mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kxw-_rmcnVu",
        "colab_type": "code",
        "outputId": "fe63f577-b62c-451f-baf7-e480cb3f32cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def get_data(filename):\n",
        "  # You will need to write code that will read the file passed\n",
        "  # into this function. The first line contains the column headers\n",
        "  # so you should ignore it\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\n",
        "  # The first value is the label\n",
        "  # The rest are the pixel values for that picture\n",
        "  # The function will return 2 np.array types. One with all the labels\n",
        "  # One with all the images\n",
        "  #\n",
        "  # Tips: \n",
        "  # If you read a full line (as 'row') then row[0] has the label\n",
        "  # and row[1:785] has the 784 pixel values\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
        "  # You are reading in strings, but need the values to be floats\n",
        "  # Check out np.array().astype for a conversion\n",
        "    images_list = []\n",
        "    labels_list = []    \n",
        "    with open(filename) as training_file:\n",
        "      training_file.readline()\n",
        "      print(\"working with %s\" % filename)\n",
        "      # Your code starts here\n",
        "      for _, line in enumerate(training_file):\n",
        "        row = [int(i) for i in line.split(',')]\n",
        "        labels_list.append(row[0])\n",
        "        images_list.append(row[1:785])\n",
        "        \n",
        "      images = np.reshape(images_list, (-1,28,28))\n",
        "      labels = np.array(labels_list)\n",
        "      \n",
        "      # Your code ends here\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "training_images, training_labels = get_data('sign_mnist_train.csv')\n",
        "testing_images, testing_labels = get_data('sign_mnist_test.csv')\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28)\n",
        "# (27455,)\n",
        "# (7172, 28, 28)\n",
        "# (7172,)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "working with sign_mnist_train.csv\n",
            "working with sign_mnist_test.csv\n",
            "(27455, 28, 28)\n",
            "(27455,)\n",
            "(7172, 28, 28)\n",
            "(7172,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIyNMkiA-7Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images_retyped = training_images.astype('uint8')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gmwagsYTRQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 32\n",
        "img_resized = cv2.resize(training_images_retyped[0], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JiJnlEr-Wvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "imageio.imwrite('first_image.jpg', img_resized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdTW66pc_IVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "870b56f0-132e-46cc-9b10-6eec53132f01"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_image.jpg  gdrive  sample_data  sign_mnist_test.csv  sign_mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVQ2h8XwR2GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe070715-f316-40af-c5d7-310b0f7dfee3"
      },
      "source": [
        "img_gray = np.expand_dims(training_images[0], 2)\n",
        "img_gray.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVPF5WH9BXBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "3103ecf5-5dec-4473-967e-f81f8a85eb95"
      },
      "source": [
        "plt.imshow(training_images[0], cmap='gray');"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnygoJj9RUEx+oqCY/ERBMfmJgvp/EEYCHUSp9mIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv5rl0eC_PNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "82d7f44f-20f0-49d0-b20b-fe12b1a2a21e"
      },
      "source": [
        "image = cv2.imread('first_image.jpg')\n",
        "plt.imshow(image);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFKhJREFUeJzt3V+MXdV1x/Hvwtge/xubwdgM5o+N\nC6pQ1AAaIaqgiCZKRKNIgFQh/IB4QHFUBalI6YNFpUKlPpCqgHioqExBIRXlTwMIVKE2FEVCeSEM\nFMwft40DRrExHoOxx//NmNWHe6yO0d1r7ux7zrkz2b+PZPn67HvuWff4rrlzz7prb3N3RKQ8Zw06\nABEZDCW/SKGU/CKFUvKLFErJL1IoJb9IoZT8IoVS8osUSskvUqiz+9nZzG4AHgIWAP/k7vdF91+y\nZIkPDw+nHiu531lndf8ZFe3TxFhKKj6A6BuUdccRyY3xyy+/TI4tWLAgOZaKv+1vlM6VONqyb98+\nJicne3rxZCe/mS0A/gH4DrALeN3MXnT391P7DA8Ps2nTpq5jixYtSh5raGio6/bFixcn91m4cGFy\n7Oyz0087Gku92KM4Tp48mRyLYoweMycho/M7NTWVHDt69Ghy7Jxzzpl1HNH5iH5ARaLzkTrHucnf\nxA+NOh9zy5YtPd+3n1/7rwF2uPsH7n4SeAq4sY/HE5EW9ZP864DfTfv3rmqbiMwDjV/wM7PNZjZu\nZuPHjh1r+nAi0qN+kn83cNG0f19YbTuDu2919zF3H1uyZEkfhxOROvWT/K8Dl5nZBjNbBNwKvFhP\nWCLStOyr/e4+ZWZ3Av9Bp9T3mLu/N9N+dZewctQdQ+7V2tw46r7iHMWxd+/erMdcvnz5rPfJKR22\nLYqj7tdB0+XIvur87v4S8FJNsYhIi/QNP5FCKflFCqXkFymUkl+kUEp+kUL1dbV/tsws2bwRNXXU\nuc/pOOocy+3cy21kySkB5T7niYmJ5Fj0pa1UY1LUYJRb6osae1JjTZz7uku3TZc39c4vUiglv0ih\nlPwihVLyixRKyS9SqFav9kO9V+7bnsOv7vn9cq84R3JijK6WnzhxIjkWXflOXbmPrujnno+c55zb\noNNEM9agmpb0zi9SKCW/SKGU/CKFUvKLFErJL1IoJb9IoeZ1qW+uNPbklmpy44ieW1RKS4lW0YnK\ngFGMOXFEx2ri/7POfdpWx/x+eucXKZSSX6RQSn6RQin5RQql5BcplJJfpFB9lfrMbCdwCDgFTLn7\n2Az3zyrbpUovTZR/6o4jt5srGjv77PR/28KFC7tuP3XqVHKfaPXkqamp5FgkZ77DKMa6/8+aUHfn\nXs7jzeY4ddT5/8TdP63hcUSkRfq1X6RQ/Sa/A78wszfMbHMdAYlIO/r9tf86d99tZmuAl83sv939\n1el3qH4obAYYHh7u83AiUpe+3vndfXf19wTwPHBNl/tsdfcxdx9bunRpP4cTkRplJ7+ZLTOzFadv\nA98F3q0rMBFpVj+/9q8Fnq9KC2cD/+Lu/z7TTnN9As9ITqkv6lTLLQ1FHXOpMuAXX3yR3Of48ePJ\nsUhOHHNlIsu5NBHnoJbryk5+d/8A+HqNsYhIi1TqEymUkl+kUEp+kUIp+UUKpeQXKVTrE3jmyOlg\nmivr8dUx0eJX5ax3F8URTeAZdRAuWrQoObZ48eKu26POvdzJQqP9UmPR84rkrvGX85hNvHam0zu/\nSKGU/CKFUvKLFErJL1IoJb9IoVq92m9mySvVOVew277anxqLmmaGhoaSY6n59mZ6zOgqcOoKfDRP\n34cffpgci+ZgWLlyZXIsVUFIVQEgPvcnTpxIjq1YsSI5lnreUYWmCdH/WWosZ5/Z0Du/SKGU/CKF\nUvKLFErJL1IoJb9IoZT8IoWaF409KXOl1BeV7CJRuSZnTkNIxxiVHM8999zkWNQAE5UjUw01UexL\nlixJjkWl4Jx5EtucLzCXGntEpBFKfpFCKflFCqXkFymUkl+kUEp+kULNWOozs8eA7wMT7v61atsI\n8DSwHtgJ3OLun/dywDo79OZDqS93ua6otBWNpWKMFkldu3Ztcixayuvw4cPJsdRzi87VsmXLkmNR\niXBqaio5ljNXX9tLeQ2qHNnLO/9PgRu+sm0L8Iq7Xwa8Uv1bROaRGZPf3V8F9n9l843A49Xtx4Gb\nao5LRBqW+5l/rbvvqW5/QmfFXhGZR/q+4OedDyzJDztmttnMxs1s/OjRo/0eTkRqkpv8e81sFKD6\neyJ1R3ff6u5j7j4WXXQSkXblJv+LwO3V7duBF+oJR0Ta0kup70ngemC1me0C7gHuA54xszuAj4Bb\nej1gqnyR08VWd+db7ljuUlJRGSqa6DIq9aXKRtE+0QSYBw4cSI5Fpb7UOYmeV9TVF03gGYmeW91y\nl/JKvVaj104dZkx+d9+UGPp2zbGISIv0DT+RQin5RQql5BcplJJfpFBKfpFCtb5WX51lu9ySXW6J\nMGd9tyiOqPyWWnNvpsdMlYdSa+fNNPbZZ58lx6L1/1Jf6IpKb1HHX1Tqi87H8uXLu25ve62+HFGM\ndXQCzv0zICKNUPKLFErJL1IoJb9IoZT8IoVS8osUqvW1+uqcjLOJkl3dJceofBWV83I69yC9ft6R\nI0eS+0TlvGgCz2gsVeqL1veLugSjUl/U/ZaanDTqICyF3vlFCqXkFymUkl+kUEp+kUIp+UUKNa+v\n9s+V5bqiq/ZR9SCazy6KI1qe6tSpU123R1f7P/3001k/3kxjKVGFIHe/qMFoZGSk6/aLL744K47f\nJ3rnFymUkl+kUEp+kUIp+UUKpeQXKZSSX6RQvSzX9RjwfWDC3b9WbbsX+AGwr7rb3e7+Ui8HnAul\nvrrlNuhEy3VFZbSokSVnDr/chpqcpp+o9Bk9XrTC8+TkZHIsNYdfVOrLfe1EDVe5S3k1qZd3/p8C\nN3TZ/qC7X1n96SnxRWTumDH53f1VYH8LsYhIi/r5zH+nmW0zs8fM7JzaIhKRVuQm/8PARuBKYA9w\nf+qOZrbZzMbNbDz6iqmItCsr+d19r7ufcvcvgUeAa4L7bnX3MXcfW7ZsWW6cIlKzrOQ3s9Fp/7wZ\neLeecESkLb2U+p4ErgdWm9ku4B7gejO7EnBgJ/DDBmNMloeiUlnuPH1Rp11q3rdVq1Yl94lijLrp\nPv744+RYNA9eqtQXdb6Njo4mx3bs2JEci7oL9+7d23V7dD5WrlyZHIvmQoxKZfv3d79WHZVSc5dY\ny10CLHW8qKRbx3JdMya/u2/qsvnRno8gInOSvuEnUiglv0ihlPwihVLyixRKyS9SqFYn8DSz1rrt\n2uzqyyk1AezatStr7MCBA8mxVEkvKmGuWbMmORZ1LEZlu1Q3YNQlGH0JLNWdB3kTiUavj7pLdrma\nfg3rnV+kUEp+kUIp+UUKpeQXKZSSX6RQSn6RQrW+Vl9K3RN4timK4+DBg8mxPXv2JMd2796dHIs6\n/j7//POu2y+88MLkPrnr1kVdZ6nOw9yJSaOSY3T+ly5d2nV71J3XxDqPOVTqE5FGKPlFCqXkFymU\nkl+kUEp+kUK1frU/1TTR5nJduVdR6646RA1B0ZXvaOmt1JJX0bx/UfzRdOvRvICpx0zNgwhxo1A0\nX2A0v9/atWu7bo+u9kfarDBFDUZ1LPGld36RQin5RQql5BcplJJfpFBKfpFCKflFCtXLcl0XAT8D\n1tJZnmuruz9kZiPA08B6Okt23eLu3btKzny8rtujskbdpb5Izn5RGSqaO2/FihXJsWg+u2i/VBkw\nKg1NTEwkx44ePZoci553aumt6HlFr4HJycnk2PDwcHJs9erVXbfnlvpy5ZTmotdiHct19fLOPwX8\n2N2vAK4FfmRmVwBbgFfc/TLglerfIjJPzJj87r7H3d+sbh8CtgPrgBuBx6u7PQ7c1FSQIlK/WX3m\nN7P1wFXAa8Badz/dkP4JnY8FIjJP9Jz8ZrYceBa4y93P+ADmnQ8gXT+EmNlmMxs3s/Hoq6Ii0q6e\nkt/MFtJJ/Cfc/blq814zG63GR4GuV43cfau7j7n7WHSxR0TaNWPyW+fy4aPAdnd/YNrQi8Dt1e3b\ngRfqD09EmtJLV983gNuAd8zsrWrb3cB9wDNmdgfwEXDLTA9kZq119c0UR52iJaii8lXU4Zaaew7i\npatSpbkoxmguwaGhoeRYVMYcGRnpuj3qwIs6D6OxqGyXOle5pb6oZJfbaZd6PUaPV8dreMbkd/df\nAakjfbvvCERkIPQNP5FCKflFCqXkFymUkl+kUEp+kULN6+W6ch+vblFJJlqeKhKV0XImwYwmBI3O\nVWoCTIjLdqlS5aFDh5L7ROcx1SUIcP755yfHUh1/UQk2Ep3HujX9utc7v0ihlPwihVLyixRKyS9S\nKCW/SKGU/CKFar3UV2cJrs1yXnS8qEMsKg1Fpa1FixYlx6IyYKr8Fp2rVAcewKpVq5JjUckx5eDB\ng8mxqHR4wQUXJMfWrVuXHEtNdhp1CUaaeM3Vse5eDr3zixRKyS9SKCW/SKGU/CKFUvKLFKrVq/3u\nnrz6HTXA5DRTRFfLc5s6jh07Nutj5TaCRHPuRUtopSoPUYzHjx9PjkVXxaPZmFNX9aPnFTURXXzx\nxcmx6Gp/HctaTRe9duqe36/pKoDe+UUKpeQXKZSSX6RQSn6RQin5RQql5Bcp1IylPjO7CPgZnSW4\nHdjq7g+Z2b3AD4B91V3vdveXcgOJSig5ZZncElsUR2osKodFZbRoLIo/auxJld9Sc/tB3FAT2b9/\nf3IsNVdf1AwUlfqiJcpyRK+pppfJ6vV4uTH2qpc6/xTwY3d/08xWAG+Y2cvV2IPu/vd9RyEiretl\nrb49wJ7q9iEz2w6kv1UhIvPCrD7zm9l64CrgtWrTnWa2zcweM7Nzao5NRBrUc/Kb2XLgWeAud58E\nHgY2AlfS+c3g/sR+m81s3MzGjxw5UkPIIlKHnpLfzBbSSfwn3P05AHff6+6n3P1L4BHgmm77uvtW\ndx9z97Hou+Ai0q4Zk986lxwfBba7+wPTto9Ou9vNwLv1hyciTenlav83gNuAd8zsrWrb3cAmM7uS\nTvlvJ/DDmR7IzJLli6jEFs2RlxKVynLKeU3EEXUyRnFEpb6pqala44jKkVF3YSqOqDvvkksuSY6l\nlt2Cub+cWxPqiL+Xq/2/ArodKbumLyKDp2/4iRRKyS9SKCW/SKGU/CKFUvKLFKr15bpSojJa7oSb\nKVGZJIojp9SXe6yoCy96zFSJLZo4M3cs6tA777zzum6PynmrV69Ojg0NDSXHoq7K1GsnKn020fGX\nM7lnTufebEqAeucXKZSSX6RQSn6RQin5RQql5BcplJJfpFCtl/pyuvpySn3RPtG6ddFklqnYJycn\nk/uk1vcDOHnyZNZYVH5LHS/aJzpXUUns0ksvTY5dfvnlXbdH5byoWzFSd3k2Uvd6fJB+XWmtPhFp\nhJJfpFBKfpFCKflFCqXkFymUkl+kUHOmqy9HVKKKSnZRh1hUGkp1zKXWpQM4ePBg1tjhw4ezxlIl\nvahkFz3nkZGR5Nj69euTYxs3bpz1saIYo7JXzjqPuRNg1t25F401vVaf3vlFCqXkFymUkl+kUEp+\nkUIp+UUKNePVfjMbAl4FFlf3/7m732NmG4CngHOBN4Db3D3djfL/j9dfxD0+VtS8E13tjx4ztazV\n0qVLk/scOHAgORY1/UQVhGgJrdQV8+h5RVfLUw06AKOjo8mx1Px+0dJgua+NnCvp0XNuuqFmrujl\nnf8E8C13/zqd5bhvMLNrgZ8AD7r7HwCfA3c0F6aI1G3G5PeO04XlhdUfB74F/Lza/jhwUyMRikgj\nevrMb2YLqhV6J4CXgd8CB9z99LdedgHrmglRRJrQU/K7+yl3vxK4ELgG+MNeD2Bmm81s3MzGjxw5\nkhmmiNRtVlf73f0A8Evgj4FVZnb6guGFwO7EPlvdfczdx5YtW9ZXsCJSnxmT38zOM7NV1e0lwHeA\n7XR+CPxZdbfbgReaClJE6tdLY88o8LiZLaDzw+IZd/83M3sfeMrM/hb4L+DRpoLMaXyIGkiipp+c\nMs+aNWuSY1HzTiTVRARxuSxH1FCzYcOG5Fj0m1w0B2FK7v9LdK5yXjtNLNeVI+dYs4lhxuR3923A\nVV22f0Dn87+IzEP6hp9IoZT8IoVS8osUSskvUiglv0ihrM0OJjPbB3xU/XM18GlrB09THGdSHGea\nb3Fc4u7n9fKArSb/GQc2G3f3sYEcXHEoDsWhX/tFSqXkFynUIJN/6wCPPZ3iOJPiONPvbRwD+8wv\nIoOlX/tFCjWQ5DezG8zsf8xsh5ltGUQMVRw7zewdM3vLzMZbPO5jZjZhZu9O2zZiZi+b2W+qv88Z\nUBz3mtnu6py8ZWbfayGOi8zsl2b2vpm9Z2Z/UW1v9ZwEcbR6TsxsyMx+bWZvV3H8TbV9g5m9VuXN\n02aWnqW2F+7e6h9gAZ1pwC4FFgFvA1e0HUcVy05g9QCO+03gauDdadv+DthS3d4C/GRAcdwL/GXL\n52MUuLq6vQL4X+CKts9JEEer5wQwYHl1eyHwGnAt8Axwa7X9H4E/7+c4g3jnvwbY4e4feGeq76eA\nGwcQx8C4+6vA/q9svpHORKjQ0oSoiTha5+573P3N6vYhOpPFrKPlcxLE0SrvaHzS3EEk/zrgd9P+\nPcjJPx34hZm9YWabBxTDaWvdfU91+xNg7QBjudPMtlUfCxr/+DGdma2nM3/EawzwnHwlDmj5nLQx\naW7pF/yuc/ergT8FfmRm3xx0QND5yU/nB9MgPAxspLNGwx7g/rYObGbLgWeBu9x9cvpYm+ekSxyt\nnxPvY9LcXg0i+XcDF037d3Lyz6a5++7q7wngeQY7M9FeMxsFqP6eGEQQ7r63euF9CTxCS+fEzBbS\nSbgn3P25anPr56RbHIM6J9WxZz1pbq8GkfyvA5dVVy4XAbcCL7YdhJktM7MVp28D3wXejfdq1It0\nJkKFAU6IejrZKjfTwjmxzsRzjwLb3f2BaUOtnpNUHG2fk9YmzW3rCuZXrmZ+j86V1N8CfzWgGC6l\nU2l4G3ivzTiAJ+n8+vgFnc9ud9BZ8/AV4DfAfwIjA4rjn4F3gG10km+0hTiuo/Mr/TbgrerP99o+\nJ0EcrZ4T4I/oTIq7jc4Pmr+e9pr9NbAD+FdgcT/H0Tf8RApV+gU/kWIp+UUKpeQXKZSSX6RQSn6R\nQin5RQql5BcplJJfpFD/B97LoVgFw0pcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "205STce-AqIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "5bcea1a8-a517-40c7-b826-88dd98fd7805"
      },
      "source": [
        "image_clr = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_clr);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQin5RQql5BcplJJfpFD/B97LoVgFw0pcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eG7AEErBBxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6393c2bd-98e2-46cf-d00d-ca40004a2176"
      },
      "source": [
        "print(training_images[0].shape)\n",
        "print(image.shape)\n",
        "print(image_clr.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SU00JlUXxsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 32\n",
        "\n",
        "TRAIN_DATA_DIR = \"/tmp/train_signs/\"\n",
        "VALIDATION_DATA_DIR = \"/tmp/test_signs/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9cBR8ecBYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "80878f75-b4c2-4535-b5bd-575937cf9a64"
      },
      "source": [
        "!rm -r $TRAIN_DATA_DIR\n",
        "!rm -r $VALIDATION_DATA_DIR\n",
        "\n",
        "!mkdir $TRAIN_DATA_DIR\n",
        "!mkdir $VALIDATION_DATA_DIR"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/tmp/train_signs/': No such file or directory\n",
            "rm: cannot remove '/tmp/test_signs/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6sphKLJUSAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a3e783f3-a922-490e-f06f-3af91ab58fd2"
      },
      "source": [
        "def images_to_rgb(images_array, labels_array, save_dir, target_size):\n",
        "  \n",
        "  for label in np.unique(labels_array):\n",
        "    label_dir = os.path.join(save_dir, str(label))\n",
        "    try:\n",
        "      os.stat(label_dir)\n",
        "    except:\n",
        "      os.mkdir(label_dir) \n",
        "    \n",
        "  count = 0\n",
        "  images_array_retyped = images_array.astype('uint8')\n",
        "  for ar, label in zip(images_array_retyped, labels_array):\n",
        "    img_resized = cv2.resize(ar, (target_size, target_size), interpolation=cv2.INTER_LINEAR)\n",
        "    filename = os.path.join(save_dir, str(label), \"{}.jpg\".format(str(count)))\n",
        "    imageio.imwrite(filename, img_resized)\n",
        "    count += 1\n",
        "    \n",
        "  # after done \n",
        "  print(count, \"images\")\n",
        "  \n",
        "\n",
        "training_images_rgb = images_to_rgb(training_images, training_labels, TRAIN_DATA_DIR, IMG_SIZE)\n",
        "testing_images_rgb = images_to_rgb(testing_images, testing_labels, VALIDATION_DATA_DIR, IMG_SIZE)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27455 images\n",
            "7172 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2W1igRzc_Vy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "92fdfe8c-748c-46f7-db6f-f9f85d69402e"
      },
      "source": [
        "print(len(os.listdir(TRAIN_DATA_DIR)))\n",
        "print(len(os.listdir(VALIDATION_DATA_DIR)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awoqRpyZdQkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this section you will have to add another dimension to the data\n",
        "# So, for example, if your array is (10000, 28, 28)\n",
        "# You will need to make it (10000, 28, 28, 1)\n",
        "# Hint: np.expand_dims\n",
        "\n",
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUX1w359fqbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e5c37cf2-5478-4fb9-992e-76105018a361"
      },
      "source": [
        "BS = 32\n",
        "\n",
        "train_data_iterator = \\\n",
        "  train_datagen.flow_from_directory(TRAIN_DATA_DIR, \n",
        "                                    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                    batch_size=BS,\n",
        "                                    class_mode=\"categorical\"\n",
        "                                   )\n",
        "validation_data_iterator = \\\n",
        "  validation_datagen.flow_from_directory(TRAIN_DATA_DIR, \n",
        "                                         target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                         batch_size=BS,\n",
        "                                         class_mode=\"categorical\"\n",
        "                                        )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27455 images belonging to 24 classes.\n",
            "Found 27455 images belonging to 24 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNDf0HwOqrVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = len(np.unique(training_labels))\n",
        "print(NUM_CLASSES)\n",
        "\n",
        "# training_labels_cat = tf.keras.utils.to_categorical(training_labels, dtype='int')\n",
        "# testing_labels_cat = tf.keras.utils.to_categorical(testing_labels, dtype='int')\n",
        "# print(training_labels_cat[0])\n",
        "# print(testing_labels_cat[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrqfFSyziW5T",
        "colab_type": "text"
      },
      "source": [
        "## Use Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WebdzbtzSPku",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751 <br>\n",
        "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lvrEzGGIU4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXYBeglnLXU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget --no-check-certificate \\\n",
        "#     https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "#     -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd2qhrKKIz8P",
        "colab_type": "code",
        "outputId": "02ddd5e9-78ec-443b-e153-6a3816f6aa35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pre_trained_model = InceptionV3(input_shape = (75, 75, 3), \n",
        "                                include_top = False, \n",
        "                                weights = \"imagenet\")\n",
        "# local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "# pre_trained_model.load_weights(\"imagenet\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 08:15:16.928900 140558378395520 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wikhVDdKAwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.applications import ResNet50\n",
        "# pre_trained_model = ResNet50(input_shape = (28, 28, 1), \n",
        "#                                 include_top = False, \n",
        "#                                 weights = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsUGNoiMPYtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cf1be7a-2d81-414d-f33c-00a779dba22b"
      },
      "source": [
        "pre_trained_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 37, 37, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 37, 37, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 37, 37, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 35, 35, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 35, 35, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 35, 35, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 35, 35, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 35, 35, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 35, 35, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 17, 17, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 17, 17, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 17, 17, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 15, 15, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 15, 15, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 15, 15, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 64)     192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 7, 7, 64)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 48)     9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 96)     55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 48)     144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 96)     288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 7, 7, 48)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 7, 7, 96)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 7, 7, 192)    0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 64)     76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 7, 7, 96)     82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 32)     6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 7, 7, 64)     192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 64)     192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 96)     288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 32)     96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 7, 7, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 7, 7, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 7, 7, 96)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 7, 7, 32)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 7, 7, 64)     192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 7, 7, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 7, 7, 96)     55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 7, 7, 48)     144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 7, 7, 96)     288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 7, 7, 48)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 7, 7, 96)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 7, 7, 64)     76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 7, 7, 96)     82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 7, 7, 64)     16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 7, 7, 64)     192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 7, 7, 64)     192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 7, 7, 96)     288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 7, 7, 64)     192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 7, 7, 64)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 7, 7, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 7, 7, 96)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 7, 7, 64)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 64)     192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 7, 7, 64)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 96)     55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 7, 7, 48)     144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 96)     288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 7, 7, 48)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 7, 7, 96)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 7, 7, 64)     76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 96)     82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 7, 7, 64)     18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 7, 7, 64)     192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 7, 7, 64)     192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 96)     288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 7, 7, 64)     192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 7, 7, 64)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 7, 7, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 7, 7, 96)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 7, 7, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 7, 7, 64)     192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 7, 7, 64)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 96)     55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 7, 7, 96)     288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 96)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 3, 3, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 3, 3, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 3, 3, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 3, 3, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 3, 3, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 3, 3, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 3, 3, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 3, 3, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 3, 3, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 3, 3, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 3, 3, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 3, 3, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 3, 3, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 3, 3, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 3, 3, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 3, 3, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 3, 3, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 3, 3, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 3, 3, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 3, 3, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 3, 3, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 3, 3, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 3, 3, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 3, 3, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 3, 3, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 3, 3, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 3, 3, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 3, 3, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 3, 3, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 3, 3, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 3, 3, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 3, 3, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 3, 3, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 3, 3, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 3, 3, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 3, 3, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 3, 3, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 3, 3, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 3, 3, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 3, 3, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 3, 3, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 3, 3, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 3, 3, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 3, 3, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 3, 3, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 3, 3, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 3, 3, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 3, 3, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 3, 3, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 3, 3, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 3, 3, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 3, 3, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 3, 3, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 3, 3, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 3, 3, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 3, 3, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 3, 3, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 3, 3, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 3, 3, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 3, 3, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 3, 3, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 3, 3, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 3, 3, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 3, 3, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 3, 3, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 3, 3, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 3, 3, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 3, 3, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 3, 3, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 3, 3, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 3, 3, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 3, 3, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 3, 3, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 3, 3, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 3, 3, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 3, 3, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 3, 3, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 3, 3, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 3, 3, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 3, 3, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 3, 3, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 3, 3, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 3, 3, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 3, 3, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 3, 3, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 3, 3, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 3, 3, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 3, 3, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 3, 3, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 3, 3, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 3, 3, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 3, 3, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 3, 3, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 3, 3, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 3, 3, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 3, 3, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 3, 3, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 3, 3, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 3, 3, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 3, 3, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 3, 3, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 3, 3, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 3, 3, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 3, 3, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 1, 1, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 1, 1, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 1, 1, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 1, 1, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 1, 1, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 1, 1, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 1, 1, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 1, 1, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 1, 1, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 1, 1, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 1, 1, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 1, 1, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 1, 1, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 1, 1, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 1, 1, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 1, 1, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 1, 1, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 1, 1, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 1, 1, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 1, 1, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 1, 1, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 1, 1, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 1, 1, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 1, 1, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 1, 1, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 1, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 1, 1, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 1, 1, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 1, 1, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 1, 1, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 1, 1, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 1, 1, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 1, 1, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 1, 1, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 1, 1, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 1, 1, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 1, 1, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 1, 1, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 1, 1, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 1, 1, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 1, 1, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 1, 1, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 1, 1, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 1, 1, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 1, 1, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 1, 1, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 1, 1, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgJjbZAKizJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, \\\n",
        "  GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "def build_tl_model(original_model, num_classes, num_layer_to_drop=0, save_file=None):\n",
        "  \"\"\"\n",
        "  Perform 'surgery' on a pretrained model. Then add layers to create a new model\n",
        "  that has just one final, trainable layer with softmax activation for \n",
        "  multi-class output.\n",
        "  \"\"\"\n",
        "  # ______________________________________________________________________________\n",
        "  # Extract needed info from pre-trained model.\n",
        "  bottleneck_input  = original_model.get_layer(index=0).input\n",
        "  bottleneck_output = original_model.get_layer('mixed5').output\n",
        "  bottleneck_model = Model(inputs=bottleneck_input, outputs=bottleneck_output)\n",
        "\n",
        "  # ______________________________________________________________________________\n",
        "  # Freeze these layers so we are not retraining the full model. \n",
        "  for layer in bottleneck_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # ______________________________________________________________________________\n",
        "  # Build new transfer learning model.\n",
        "  new_model = Sequential()\n",
        "  new_model.add(bottleneck_model)\n",
        "#   new_model.add(Conv2D(36, kernel_size=(3,3), activation='relu'))\n",
        "  new_model.add(GlobalAveragePooling2D())\n",
        "  new_model.add(Dense(128, activation=\"relu\"))\n",
        "  new_model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "#   NUM_CLASSES = len(os.listdir(IMG_DIR))  # How many image classes are in our new data?\n",
        "  BOTTLENECK_DIM = bottleneck_output.shape.dims[1]  # The number of nodes in the second to last layer of the pre-trained model.\n",
        "  print(BOTTLENECK_DIM)                    \n",
        "\n",
        "  if save_file:\n",
        "    new_model.save(save_file)\n",
        "\n",
        "  return new_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqjsiLpCndD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e9431470-8034-4768-e004-cb687bab2225"
      },
      "source": [
        "transfer_model = build_tl_model(pre_trained_model, num_classes=NUM_CLASSES)\n",
        "transfer_model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_3 (Model)              (None, 3, 3, 768)         5138656   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               98432     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 5,240,184\n",
            "Trainable params: 101,528\n",
            "Non-trainable params: 5,138,656\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1oELXbndNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model. \n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "transfer_model.compile(optimizer=RMSprop(lr=1e-2), loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nujki8g1ndWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "transfer_checkpoint = ModelCheckpoint(filepath='transfer_model.h5',\n",
        "                             monitor='val_acc', \n",
        "                             save_best_only=True, \n",
        "                             load_weights_on_restart=True,\n",
        "                            )\n",
        "transfer_earlystopping = EarlyStopping(monitor='val_acc',\n",
        "                             patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isnGTupJt_6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05985b97-8ccd-4052-faea-403ccd7c5df1"
      },
      "source": [
        "BS = 64\n",
        "\n",
        "transfer_train_data_iterator = \\\n",
        "  train_datagen.flow_from_directory(TRAIN_DATA_DIR, \n",
        "                                    target_size=(75, 75),\n",
        "                                    batch_size=BS,\n",
        "                                    class_mode=\"categorical\"\n",
        "                                   )\n",
        "transfer_validation_data_iterator = \\\n",
        "  validation_datagen.flow_from_directory(TRAIN_DATA_DIR, \n",
        "                                         target_size=(75, 75),\n",
        "                                         batch_size=BS,\n",
        "                                         class_mode=\"categorical\"\n",
        "                                        )"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27455 images belonging to 24 classes.\n",
            "Found 27455 images belonging to 24 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXLwUc4_tjVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "00b2c42d-4aed-44c9-834b-5905418c76b9"
      },
      "source": [
        "# Train the Model\n",
        "EPOCHS = 20\n",
        "\n",
        "transfer_history = transfer_model.fit_generator(\n",
        "     transfer_train_data_iterator,\n",
        "\t   validation_data=transfer_validation_data_iterator,\n",
        "\t   steps_per_epoch=len(training_images) // BS,\n",
        "     epochs=EPOCHS,\n",
        "     callbacks=[transfer_checkpoint, transfer_earlystopping]\n",
        ")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "428/428 [==============================] - 128s 300ms/step - loss: 0.9318 - acc: 0.6881 - val_loss: 5.2742 - val_acc: 0.2853\n",
            "Epoch 2/20\n",
            "428/428 [==============================] - 127s 296ms/step - loss: 0.8405 - acc: 0.7176 - val_loss: 5.1409 - val_acc: 0.2818\n",
            "Epoch 3/20\n",
            "428/428 [==============================] - 199s 465ms/step - loss: 0.7717 - acc: 0.7437 - val_loss: 6.4026 - val_acc: 0.2924\n",
            "Epoch 4/20\n",
            "428/428 [==============================] - 203s 475ms/step - loss: 0.7494 - acc: 0.7544 - val_loss: 4.0921 - val_acc: 0.3879\n",
            "Epoch 5/20\n",
            "428/428 [==============================] - 198s 463ms/step - loss: 0.7272 - acc: 0.7632 - val_loss: 4.7368 - val_acc: 0.3367\n",
            "Epoch 6/20\n",
            "428/428 [==============================] - 198s 463ms/step - loss: 0.7190 - acc: 0.7687 - val_loss: 5.0588 - val_acc: 0.3674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oS3duzLt3Cn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "863c0258-684b-41d2-cfec-6193709f60d2"
      },
      "source": [
        "transfer_model.evaluate_generator(transfer_train_data_iterator)\n",
        "    \n",
        "# The output from model.evaluate should be close to:\n",
        "# [6.92426086682151, 0.56609035]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.051161848859631, 0.37064287]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjVIlMRgx4eN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "ca0bcd9d-33f0-43cb-c2c6-573764fcb974"
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "history = transfer_history\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgaAoEcqYBDw",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Not the best approach for this task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BxnTlxAZd04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}