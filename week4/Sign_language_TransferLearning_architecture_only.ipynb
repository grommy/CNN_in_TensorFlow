{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sign_language_TransferLearning-architecture-only.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grommy/CNN_in_TensorFlow/blob/master/week4/Sign_language_TransferLearning_architecture_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYtuKeK0dImp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMyh9_mkDHF",
        "colab_type": "text"
      },
      "source": [
        "The data for this exercise is available at: https://www.kaggle.com/datamunge/sign-language-mnist/home\n",
        "\n",
        "Sign up and download to find 2 CSV files: sign_mnist_test.csv and sign_mnist_train.csv -- You will upload both of them using this button before you can continue.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x54LORXJ5oli",
        "colab_type": "code",
        "outputId": "1a71cfc2-154f-42f0-9d96-d6b46f7f51e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkD5xbhm6Fpf",
        "colab_type": "code",
        "outputId": "4f8e20dc-f97c-4b22-f12f-a0881378277a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks/CNN_in_TF/Week4/sign-language-mnist"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "american_sign_language.PNG  amer_sign3.png\t sign_mnist_train.csv\n",
            "amer_sign2.png\t\t    sign_mnist_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-9-sGj88ryn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/gdrive/My Drive/Colab Notebooks/CNN_in_TF/Week4/sign-language-mnist/sign_mnist_train.csv' .\n",
        "!cp '/content/gdrive/My Drive/Colab Notebooks/CNN_in_TF/Week4/sign-language-mnist/sign_mnist_test.csv' ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B40soosz2Vn_",
        "colab_type": "code",
        "outputId": "0b543787-8b04-428a-bcff-117d4f132944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "import pandas as pd\n",
        "X_train = pd.read_csv('sign_mnist_train.csv', nrows=100)\n",
        "X_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>165</td>\n",
              "      <td>159</td>\n",
              "      <td>166</td>\n",
              "      <td>168</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>172</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>169</td>\n",
              "      <td>111</td>\n",
              "      <td>121</td>\n",
              "      <td>129</td>\n",
              "      <td>135</td>\n",
              "      <td>141</td>\n",
              "      <td>144</td>\n",
              "      <td>148</td>\n",
              "      <td>151</td>\n",
              "      <td>154</td>\n",
              "      <td>157</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>205</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>142</td>\n",
              "      <td>151</td>\n",
              "      <td>160</td>\n",
              "      <td>172</td>\n",
              "      <td>196</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>190</td>\n",
              "      <td>135</td>\n",
              "      <td>96</td>\n",
              "      <td>86</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>176</td>\n",
              "      <td>205</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>154</td>\n",
              "      <td>153</td>\n",
              "      <td>152</td>\n",
              "      <td>151</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>148</td>\n",
              "      <td>147</td>\n",
              "      <td>146</td>\n",
              "      <td>144</td>\n",
              "      <td>142</td>\n",
              "      <td>143</td>\n",
              "      <td>138</td>\n",
              "      <td>92</td>\n",
              "      <td>108</td>\n",
              "      <td>158</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>78</td>\n",
              "      <td>120</td>\n",
              "      <td>157</td>\n",
              "      <td>168</td>\n",
              "      <td>107</td>\n",
              "      <td>99</td>\n",
              "      <td>121</td>\n",
              "      <td>133</td>\n",
              "      <td>97</td>\n",
              "      <td>95</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>116</td>\n",
              "      <td>95</td>\n",
              "      <td>79</td>\n",
              "      <td>69</td>\n",
              "      <td>86</td>\n",
              "      <td>139</td>\n",
              "      <td>173</td>\n",
              "      <td>200</td>\n",
              "      <td>185</td>\n",
              "      <td>175</td>\n",
              "      <td>198</td>\n",
              "      <td>124</td>\n",
              "      <td>118</td>\n",
              "      <td>94</td>\n",
              "      <td>140</td>\n",
              "      <td>133</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>178</td>\n",
              "      <td>178</td>\n",
              "      <td>109</td>\n",
              "      <td>52</td>\n",
              "      <td>66</td>\n",
              "      <td>77</td>\n",
              "      <td>83</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>203</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>196</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>193</td>\n",
              "      <td>198</td>\n",
              "      <td>166</td>\n",
              "      <td>132</td>\n",
              "      <td>114</td>\n",
              "      <td>89</td>\n",
              "      <td>74</td>\n",
              "      <td>79</td>\n",
              "      <td>77</td>\n",
              "      <td>74</td>\n",
              "      <td>78</td>\n",
              "      <td>132</td>\n",
              "      <td>188</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>206</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>207</td>\n",
              "      <td>208</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>198</td>\n",
              "      <td>197</td>\n",
              "      <td>195</td>\n",
              "      <td>192</td>\n",
              "      <td>197</td>\n",
              "      <td>171</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>54</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>215</td>\n",
              "      <td>215</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>...</td>\n",
              "      <td>247</td>\n",
              "      <td>242</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>229</td>\n",
              "      <td>227</td>\n",
              "      <td>225</td>\n",
              "      <td>223</td>\n",
              "      <td>221</td>\n",
              "      <td>220</td>\n",
              "      <td>216</td>\n",
              "      <td>58</td>\n",
              "      <td>51</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>159</td>\n",
              "      <td>255</td>\n",
              "      <td>237</td>\n",
              "      <td>239</td>\n",
              "      <td>237</td>\n",
              "      <td>236</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>193</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>192</td>\n",
              "      <td>192</td>\n",
              "      <td>194</td>\n",
              "      <td>194</td>\n",
              "      <td>166</td>\n",
              "      <td>169</td>\n",
              "      <td>172</td>\n",
              "      <td>174</td>\n",
              "      <td>177</td>\n",
              "      <td>180</td>\n",
              "      <td>182</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>77</td>\n",
              "      <td>88</td>\n",
              "      <td>117</td>\n",
              "      <td>123</td>\n",
              "      <td>127</td>\n",
              "      <td>129</td>\n",
              "      <td>134</td>\n",
              "      <td>145</td>\n",
              "      <td>152</td>\n",
              "      <td>156</td>\n",
              "      <td>179</td>\n",
              "      <td>105</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>175</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>152</td>\n",
              "      <td>136</td>\n",
              "      <td>130</td>\n",
              "      <td>136</td>\n",
              "      <td>150</td>\n",
              "      <td>118</td>\n",
              "      <td>92</td>\n",
              "      <td>85</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      3     107     118     127  ...       206       204       203       202\n",
              "1      6     155     157     156  ...       175       103       135       149\n",
              "2      2     187     188     188  ...       198       195       194       195\n",
              "3      2     211     211     212  ...       225       222       229       163\n",
              "4     13     164     167     170  ...       157       163       164       179\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1rlyFO282K8",
        "colab_type": "code",
        "outputId": "672f9cf8-826a-4d7b-cef3-5664c598db14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_image.jpg  model.h5     sign_mnist_test.csv   transfer_model.h5\n",
            "gdrive\t\t sample_data  sign_mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kxw-_rmcnVu",
        "colab_type": "code",
        "outputId": "c8debc38-4bb3-48ac-c580-6709aea1560e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def get_data(filename):\n",
        "  # You will need to write code that will read the file passed\n",
        "  # into this function. The first line contains the column headers\n",
        "  # so you should ignore it\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\n",
        "  # The first value is the label\n",
        "  # The rest are the pixel values for that picture\n",
        "  # The function will return 2 np.array types. One with all the labels\n",
        "  # One with all the images\n",
        "  #\n",
        "  # Tips: \n",
        "  # If you read a full line (as 'row') then row[0] has the label\n",
        "  # and row[1:785] has the 784 pixel values\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
        "  # You are reading in strings, but need the values to be floats\n",
        "  # Check out np.array().astype for a conversion\n",
        "    images_list = []\n",
        "    labels_list = []    \n",
        "    with open(filename) as training_file:\n",
        "      training_file.readline()\n",
        "      print(\"working with %s\" % filename)\n",
        "      # Your code starts here\n",
        "      for _, line in enumerate(training_file):\n",
        "        row = [int(i) for i in line.split(',')]\n",
        "        labels_list.append(row[0])\n",
        "        images_list.append(row[1:785])\n",
        "        \n",
        "      images = np.reshape(images_list, (-1,28,28))\n",
        "      labels = np.array(labels_list)\n",
        "      \n",
        "      # Your code ends here\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "training_images, training_labels = get_data('sign_mnist_train.csv')\n",
        "testing_images, testing_labels = get_data('sign_mnist_test.csv')\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28)\n",
        "# (27455,)\n",
        "# (7172, 28, 28)\n",
        "# (7172,)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "working with sign_mnist_train.csv\n",
            "working with sign_mnist_test.csv\n",
            "(27455, 28, 28)\n",
            "(27455,)\n",
            "(7172, 28, 28)\n",
            "(7172,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIyNMkiA-7Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images_retyped = training_images.astype('uint8')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gmwagsYTRQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 32\n",
        "img_resized = cv2.resize(training_images_retyped[0], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JiJnlEr-Wvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "imageio.imwrite('first_image.jpg', img_resized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdTW66pc_IVH",
        "colab_type": "code",
        "outputId": "0802b640-58f5-4bb8-8ba8-a63a755162ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_image.jpg  model.h5     sign_mnist_test.csv   transfer_model.h5\n",
            "gdrive\t\t sample_data  sign_mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVQ2h8XwR2GU",
        "colab_type": "code",
        "outputId": "9c1cdcb0-04bc-45b6-fb69-dceb5c595da5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_gray = np.expand_dims(training_images[0], 2)\n",
        "img_gray.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVPF5WH9BXBE",
        "colab_type": "code",
        "outputId": "9114499f-ddab-43b8-c56a-b3f53ad6cccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.imshow(training_images[0], cmap='gray');"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnygoJj9RUEx+oqCY/ERBMfmJgvp/EEYCHUSp9mIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv5rl0eC_PNv",
        "colab_type": "code",
        "outputId": "74063065-f131-4af6-fa43-2ae31c274b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "image = cv2.imread('first_image.jpg')\n",
        "plt.imshow(image);"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQin5RQql5BcplJJfpFD/B97LoVgFw0pcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "205STce-AqIk",
        "colab_type": "code",
        "outputId": "8a78dd43-7631-4c8f-e3f4-0ddc0a4ab689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "image_clr = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_clr);"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQin5RQql5BcplJJfpFD/B97LoVgFw0pcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eG7AEErBBxK",
        "colab_type": "code",
        "outputId": "4abc2b47-7720-4676-c535-36f18076741a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(training_images[0].shape)\n",
        "print(image.shape)\n",
        "print(image_clr.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SU00JlUXxsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 32\n",
        "\n",
        "TRAIN_DATA_DIR = \"/tmp/train_signs/\"\n",
        "VALIDATION_DATA_DIR = \"/tmp/test_signs/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9cBR8ecBYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r $TRAIN_DATA_DIR\n",
        "!rm -r $VALIDATION_DATA_DIR\n",
        "\n",
        "!mkdir $TRAIN_DATA_DIR\n",
        "!mkdir $VALIDATION_DATA_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6sphKLJUSAD",
        "colab_type": "code",
        "outputId": "70a4d047-2680-4037-a4ed-ad8bc1854950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def images_to_rgb(images_array, labels_array, save_dir, target_size):\n",
        "  \n",
        "  for label in np.unique(labels_array):\n",
        "    label_dir = os.path.join(save_dir, str(label))\n",
        "    try:\n",
        "      os.stat(label_dir)\n",
        "    except:\n",
        "      os.mkdir(label_dir) \n",
        "    \n",
        "  count = 0\n",
        "  images_array_retyped = images_array.astype('uint8')\n",
        "  for ar, label in zip(images_array_retyped, labels_array):\n",
        "    img_resized = cv2.resize(ar, (target_size, target_size), interpolation=cv2.INTER_LINEAR)\n",
        "    filename = os.path.join(save_dir, str(label), \"{}.jpg\".format(str(count)))\n",
        "    imageio.imwrite(filename, img_resized)\n",
        "    count += 1\n",
        "    \n",
        "  # after done \n",
        "  print(count, \"images\")\n",
        "  \n",
        "\n",
        "training_images_rgb = images_to_rgb(training_images, training_labels, TRAIN_DATA_DIR, IMG_SIZE)\n",
        "testing_images_rgb = images_to_rgb(testing_images, testing_labels, VALIDATION_DATA_DIR, IMG_SIZE)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27455 images\n",
            "7172 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2W1igRzc_Vy",
        "colab_type": "code",
        "outputId": "80766dd9-6335-4749-84ce-9cfd559e6222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(os.listdir(TRAIN_DATA_DIR)))\n",
        "print(len(os.listdir(VALIDATION_DATA_DIR)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNDf0HwOqrVO",
        "colab_type": "code",
        "outputId": "5b564929-a6d9-47a6-d2ad-a29e57dc3016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "NUM_CLASSES = len(np.unique(training_labels))\n",
        "print(len(np.unique(training_labels)))\n",
        "\n",
        "training_labels_cat = tf.keras.utils.to_categorical(training_labels, dtype='int')\n",
        "testing_labels_cat = tf.keras.utils.to_categorical(testing_labels, dtype='int')\n",
        "print(training_labels_cat[0])\n",
        "print(testing_labels_cat[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrqfFSyziW5T",
        "colab_type": "text"
      },
      "source": [
        "## Use Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lvrEzGGIU4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd2qhrKKIz8P",
        "colab_type": "code",
        "outputId": "f3d97d9b-ce65-414f-935c-05520fba7500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "pre_trained_model = InceptionV3(input_shape = (75, 75, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "# local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "# pre_trained_model.load_weights(\"imagenet\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 08:39:50.635696 140669239826304 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wikhVDdKAwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.applications import ResNet50\n",
        "# pre_trained_model = ResNet50(input_shape = (28, 28, 1), \n",
        "#                                 include_top = False, \n",
        "#                                 weights = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4AMf-WhL_-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84e47b7a-b0fe-43cd-9354-885f7128a09b"
      },
      "source": [
        "pre_trained_model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 75, 75, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 37, 37, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 37, 37, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 37, 37, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 35, 35, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 35, 35, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 35, 35, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 35, 35, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 35, 35, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 35, 35, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 17, 17, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 17, 17, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 17, 17, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 17, 17, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 15, 15, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 15, 15, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 15, 15, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 64)     192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 7, 7, 64)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 48)     9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 96)     55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 48)     144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 96)     288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 7, 7, 48)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 7, 7, 96)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 7, 7, 192)    0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 64)     76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 7, 7, 96)     82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 32)     6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 7, 7, 64)     192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 64)     192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 96)     288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 32)     96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 7, 7, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 7, 7, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 7, 7, 96)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 7, 7, 32)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 7, 7, 64)     192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 7, 7, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 7, 7, 96)     55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 7, 7, 48)     144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 7, 7, 96)     288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 7, 7, 48)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 7, 7, 96)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 7, 7, 64)     76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 7, 7, 96)     82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 7, 7, 64)     16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 7, 7, 64)     192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 7, 7, 64)     192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 7, 7, 96)     288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 7, 7, 64)     192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 7, 7, 64)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 7, 7, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 7, 7, 96)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 7, 7, 64)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 64)     192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 7, 7, 64)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 96)     55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 7, 7, 48)     144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 96)     288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 7, 7, 48)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 7, 7, 96)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 7, 7, 64)     76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 96)     82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 7, 7, 64)     18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 7, 7, 64)     192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 7, 7, 64)     192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 96)     288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 7, 7, 64)     192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 7, 7, 64)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 7, 7, 64)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 7, 7, 96)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 7, 7, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 7, 7, 64)     192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 7, 7, 64)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 96)     55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 7, 7, 96)     288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 96)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 3, 3, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 3, 3, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 3, 3, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 3, 3, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 3, 3, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 3, 3, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 3, 3, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 3, 3, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 3, 3, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 3, 3, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 3, 3, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 3, 3, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 3, 3, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 3, 3, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 3, 3, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 3, 3, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 3, 3, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 3, 3, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 3, 3, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 3, 3, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 3, 3, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 3, 3, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 3, 3, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 3, 3, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 3, 3, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 3, 3, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 3, 3, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 3, 3, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 3, 3, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 3, 3, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 3, 3, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 3, 3, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 3, 3, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 3, 3, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 3, 3, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 3, 3, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 3, 3, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 3, 3, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 3, 3, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 3, 3, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 3, 3, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 3, 3, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 3, 3, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 3, 3, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 3, 3, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 3, 3, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 3, 3, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 3, 3, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 3, 3, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 3, 3, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 3, 3, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 3, 3, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 3, 3, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 3, 3, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 3, 3, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 3, 3, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 3, 3, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 3, 3, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 3, 3, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 3, 3, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 3, 3, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 3, 3, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 3, 3, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 3, 3, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 3, 3, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 3, 3, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 3, 3, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 3, 3, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 3, 3, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 3, 3, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 3, 3, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 3, 3, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 3, 3, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 3, 3, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 3, 3, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 3, 3, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 3, 3, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 3, 3, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 3, 3, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 3, 3, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 3, 3, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 3, 3, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 3, 3, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 3, 3, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 3, 3, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 3, 3, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 3, 3, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 3, 3, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 3, 3, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 3, 3, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 3, 3, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 3, 3, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 3, 3, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 3, 3, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 3, 3, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 3, 3, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 3, 3, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 3, 3, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 3, 3, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 3, 3, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 3, 3, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 3, 3, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 3, 3, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 3, 3, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 3, 3, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 3, 3, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 3, 3, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 3, 3, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 3, 3, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 3, 3, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 1, 1, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 1, 1, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 1, 1, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 1, 1, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 1, 1, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 1, 1, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 1, 1, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 1, 1, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 1, 1, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 1, 1, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 1, 1, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 1, 1, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 1, 1, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 1, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 1, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 1, 1, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 1, 1, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 1, 1, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 1, 1, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 1, 1, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 1, 1, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 1, 1, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 1, 1, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 1, 1, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 1, 1, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 1, 1, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 1, 1, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 1, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 1, 1, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 1, 1, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 1, 1, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 1, 1, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 1, 1, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 1, 1, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 1, 1, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 1, 1, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 1, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 1, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 1, 1, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 1, 1, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 1, 1, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 1, 1, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 1, 1, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 1, 1, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 1, 1, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 1, 1, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 1, 1, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 1, 1, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 1, 1, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 1, 1, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 1, 1, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgJjbZAKizJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, \\\n",
        "  GlobalAveragePooling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "def build_tl_model(original_model, num_classes, num_layer_to_drop=0, save_file=None):\n",
        "  \"\"\"\n",
        "  Perform 'surgery' on a pretrained model. Then add layers to create a new model\n",
        "  that has just one final, trainable layer with softmax activation for \n",
        "  multi-class output.\n",
        "  \"\"\"\n",
        "  # ______________________________________________________________________________\n",
        "  # Extract needed info from pre-trained model.\n",
        "  bottleneck_input  = original_model.get_layer(index=0).input\n",
        "  bottleneck_output = original_model.get_layer('mixed0').output\n",
        "  bottleneck_model = Model(inputs=bottleneck_input, outputs=bottleneck_output)\n",
        "\n",
        "  # ______________________________________________________________________________\n",
        "  # Freeze these layers so we are not retraining the full model. \n",
        "#   for layer in bottleneck_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "  # ______________________________________________________________________________\n",
        "  # Build new transfer learning model.\n",
        "  new_model = Sequential()\n",
        "  new_model.add(bottleneck_model)\n",
        "#   new_model.add(Conv2D(10, kernel_size=(3,3), activation='relu'))\n",
        "  new_model.add(GlobalAveragePooling2D())\n",
        "  new_model.add(Dense(64, activation=\"relu\"))\n",
        "  new_model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "#   NUM_CLASSES = len(os.listdir(IMG_DIR))  # How many image classes are in our new data?\n",
        "  BOTTLENECK_DIM = bottleneck_output.shape.dims[1]  # The number of nodes in the second to last layer of the pre-trained model.\n",
        "  print(BOTTLENECK_DIM)                    \n",
        "\n",
        "  if save_file:\n",
        "    new_model.save(save_file)\n",
        "\n",
        "  return new_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqjsiLpCndD7",
        "colab_type": "code",
        "outputId": "53c1bce2-4af3-4758-a4fe-f7f529a4de2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "transfer_model = build_tl_model(pre_trained_model, num_classes=NUM_CLASSES)\n",
        "transfer_model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model (Model)                (None, 7, 7, 256)         429440    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 24)                1560      \n",
            "=================================================================\n",
            "Total params: 447,448\n",
            "Trainable params: 445,720\n",
            "Non-trainable params: 1,728\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1oELXbndNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile Model. \n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "transfer_model.compile(optimizer=RMSprop(lr=1e-2), loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nujki8g1ndWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "transfer_checkpoint = ModelCheckpoint(filepath='transfer_model_random_weights.h5',\n",
        "                             monitor='val_acc', \n",
        "                             save_best_only=True, \n",
        "                             load_weights_on_restart=True,\n",
        "                            )\n",
        "transfer_earlystopping = EarlyStopping(monitor='val_acc',\n",
        "                             patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awoqRpyZdQkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isnGTupJt_6F",
        "colab_type": "code",
        "outputId": "3716cbb0-91ff-47e3-d609-0052ab17a14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BS = 32\n",
        "\n",
        "transfer_train_data_iterator = \\\n",
        "  train_datagen.flow_from_directory(TRAIN_DATA_DIR, \n",
        "                                    target_size=(75, 75),\n",
        "                                    batch_size=BS,\n",
        "                                    class_mode=\"categorical\"\n",
        "                                   )\n",
        "transfer_validation_data_iterator = \\\n",
        "  validation_datagen.flow_from_directory(TRAIN_DATA_DIR, \n",
        "                                         target_size=(75, 75),\n",
        "                                         batch_size=BS,\n",
        "                                         class_mode=\"categorical\"\n",
        "                                        )"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27455 images belonging to 24 classes.\n",
            "Found 27455 images belonging to 24 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXLwUc4_tjVY",
        "colab_type": "code",
        "outputId": "3925a8ef-df5b-4880-ae39-fd5659f1a79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Train the Model\n",
        "BS = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "transfer_history = transfer_model.fit_generator(\n",
        "     transfer_train_data_iterator,\n",
        "\t   validation_data=transfer_validation_data_iterator,\n",
        "\t   steps_per_epoch=len(training_images) // BS,\n",
        "     epochs=EPOCHS,\n",
        "     callbacks=[transfer_checkpoint, transfer_earlystopping]\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "857/857 [==============================] - 216s 252ms/step - loss: 2.5580 - acc: 0.1709 - val_loss: 4.2298 - val_acc: 0.0924\n",
            "Epoch 2/10\n",
            "857/857 [==============================] - 205s 239ms/step - loss: 1.5206 - acc: 0.4688 - val_loss: 3.9881 - val_acc: 0.1978\n",
            "Epoch 3/10\n",
            "857/857 [==============================] - 201s 234ms/step - loss: 0.7950 - acc: 0.7206 - val_loss: 6.0744 - val_acc: 0.2036\n",
            "Epoch 4/10\n",
            "857/857 [==============================] - 186s 217ms/step - loss: 0.4715 - acc: 0.8413 - val_loss: 1.0059 - val_acc: 0.6858\n",
            "Epoch 5/10\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.3019 - acc: 0.8989 - val_loss: 0.9879 - val_acc: 0.7666\n",
            "Epoch 6/10\n",
            "857/857 [==============================] - 127s 148ms/step - loss: 0.2289 - acc: 0.9232 - val_loss: 0.9588 - val_acc: 0.7921\n",
            "Epoch 7/10\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.1836 - acc: 0.9414 - val_loss: 0.3994 - val_acc: 0.8777\n",
            "Epoch 8/10\n",
            "857/857 [==============================] - 126s 148ms/step - loss: 0.1474 - acc: 0.9529 - val_loss: 0.4096 - val_acc: 0.8958\n",
            "Epoch 9/10\n",
            "857/857 [==============================] - 157s 183ms/step - loss: 0.1299 - acc: 0.9608 - val_loss: 0.5736 - val_acc: 0.8418\n",
            "Epoch 10/10\n",
            "857/857 [==============================] - 122s 143ms/step - loss: 0.1162 - acc: 0.9644 - val_loss: 1.7539 - val_acc: 0.6695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0VNEspvZEQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "17e6844e-cfd5-42e6-ab8e-ce8420187e66"
      },
      "source": [
        "best_model = tf.keras.models.load_model('transfer_model_random_weights.h5')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 09:47:42.928776 140669239826304 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0718 09:47:42.935232 140669239826304 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0718 09:47:42.939209 140669239826304 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XltpAjGnDT-w",
        "colab_type": "code",
        "outputId": "3e5c5cf8-c00f-4380-c5fa-ee595a4e76da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_model.evaluate_generator(transfer_train_data_iterator)\n",
        "    \n",
        "# The output from model.evaluate should be close to:\n",
        "# [6.92426086682151, 0.56609035]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40851046258012713, 0.8966673]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q3Zpr46dsij",
        "colab_type": "code",
        "outputId": "bf9c8d04-7d97-4de7-add5-3c57cc2ff67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "history = transfer_history\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN1CkOHq6mgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VOXVwPHfARLCvqMCYlBkSSBA\nZkQUARFUQISi1OLWqkV8qVvdKrX6ahVbay3uGyq0vAJiWcQKYm2hCmpBQAExIIioYScia1gC5/3j\nmckCWSbJTO4s5/v5zGfuzNy598xMcuaZZxVVxRhjTOyo5nUAxhhjyscStzHGxBhL3MYYE2MscRtj\nTIyxxG2MMTHGErcxxsQYS9wJSESqi8g+EWkdzn29JCJtRSTsfVtFpL+IbCx0e62I9Apl3wqc61UR\nua+izy/luGNF5K/hPq7xTg2vAzBlE5F9hW7WBg4BRwO3b1LVyeU5nqoeBeqGe99EoKrtw3EcERkJ\nXKOq5xc69shwHNvEP0vcMUBV8xNnoEQ3UlX/VdL+IlJDVfOqIjZjTNWzqpI4EPgpPE1EporIXuAa\nETlHRP4rIj+KyBYReUZEkgL71xARFZHUwO3XA4+/KyJ7ReQTEWlT3n0Djw8Uka9EZLeIPCsiH4nI\ndSXEHUqMN4nIehHZJSLPFHpudRF5UkRyRGQDMKCU9+d3IvLGcfc9LyLjAtsjRSQr8Hq+DpSGSzpW\ntoicH9iuLSL/F4htNeA7bt/7RWRD4LirRWRI4P7OwHNAr0A11M5C7+1DhZ7/P4HXniMib4nIKaG8\nN2URkWGBeH4Ukfki0r7QY/eJyGYR2SMiawq91h4isjxw/zYR+XOo5zMRoKp2iaELsBHof9x9Y4HD\nwKW4L+NawFnA2bhfVacDXwG3BPavASiQGrj9OrAT8ANJwDTg9Qrs2xzYCwwNPHYncAS4roTXEkqM\ns4EGQCrwQ/C1A7cAq4FWQBPgQ/fnXOx5Tgf2AXUKHXs74A/cvjSwjwAXALlARuCx/sDGQsfKBs4P\nbD8B/AdoBJwGfHncvlcApwQ+k6sCMZwUeGwk8J/j4nwdeCiwfVEgxq5ACvACMD+U96aY1z8W+Gtg\nu2MgjgsCn9F9wNrAdjrwLXByYN82wOmB7U+BKwPb9YCzvf5fSOSLlbjjxyJV/YeqHlPVXFX9VFUX\nq2qeqm4AxgN9Snn+dFVdqqpHgMm4hFHefQcDn6vq7MBjT+KSfLFCjPGPqrpbVTfikmTwXFcAT6pq\ntqrmAI+Vcp4NwBe4LxSAC4Fdqro08Pg/VHWDOvOBfwPFNkAe5wpgrKruUtVvcaXowud9U1W3BD6T\nKbgvXX8IxwW4GnhVVT9X1YPAGKCPiLQqtE9J701pRgBvq+r8wGf0GC75nw3k4b4k0gPVbd8E3jtw\nX8BnikgTVd2rqotDfB0mAixxx4/vC98QkQ4iMkdEtorIHuBhoGkpz99aaPsApTdIlrRvi8JxqKri\nSqjFCjHGkM6FKymWZgpwZWD7qsDtYByDRWSxiPwgIj/iSrulvVdBp5QWg4hcJyIrAlUSPwIdQjwu\nuNeXfzxV3QPsAloW2qc8n1lJxz2G+4xaqupa4C7c57A9UPV2cmDX64E0YK2ILBGRQSG+DhMBlrjj\nx/Fd4V7GlTLbqmp94H9xVQGRtAVXdQGAiAhFE83xKhPjFuDUQrfL6q74JtBfRFriSt5TAjHWAqYD\nf8RVYzQE/hliHFtLikFETgdeBEYDTQLHXVPouGV1XdyMq34JHq8erkpmUwhxlee41XCf2SYAVX1d\nVXviqkmq494XVHWtqo7AVYf9BZghIimVjMVUkCXu+FUP2A3sF5GOwE1VcM53gEwRuVREagC3A80i\nFOObwK9FpKWINAHuLW1nVd0KLAL+CqxV1XWBh2oCycAO4KiIDAb6lSOG+0Skobh+7rcUeqwuLjnv\nwH2H3YgrcQdtA1oFG2OLMRX4pYhkiEhNXAJdqKol/oIpR8xDROT8wLnvwbVLLBaRjiLSN3C+3MDl\nGO4FXCsiTQMl9N2B13askrGYCrLEHb/uAn6B+6d8GdeIGFGqug34GTAOyAHOAD7D9TsPd4wv4uqi\nV+EazqaH8JwpuMbG/GoSVf0RuAOYhWvgG477AgrFg7iS/0bgXWBSoeOuBJ4FlgT2aQ8Urhd+H1gH\nbBORwlUewefPw1VZzAo8vzWu3rtSVHU17j1/EfelMgAYEqjvrgk8jmuX2Ior4f8u8NRBQJa4XktP\nAD9T1cOVjcdUjLhqSGPCT0Sq436aD1fVhV7HY0y8sBK3CSsRGRCoOqgJPIDrjbDE47CMiSuWuE24\nnQdswP0MvxgYpqolVZUYYyrAqkqMMSbGWInbGGNiTEQmmWratKmmpqZG4tDGGBOXli1btlNVS+s+\nmy8iiTs1NZWlS5dG4tDGGBOXRKSs0b/5rKrEGGNijCVuY4yJMZa4jTEmxtgKOMbEqCNHjpCdnc3B\ngwe9DsWUQ0pKCq1atSIpqaRpaspmiduYGJWdnU29evVITU3FTcRoop2qkpOTQ3Z2Nm3atCn7CSWw\nqhJjYtTBgwdp0qSJJe0YIiI0adKk0r+SLHEbE8MsaceecHxmlrij1N69MH48HLMZj40xxwkpcQdm\ne5seWPU5S0TOiXRgiW7sWLjpJli0yOtIjCleTk4OXbt2pWvXrpx88sm0bNky//bhw6FN1X399dez\ndu3aUvd5/vnnmTx5cjhC5rzzzuPzzz8Py7G8FGrj5NPAPFUdLiLJQO0IxpTwcnLg+efd9tKl0Lu3\nt/EYU5wmTZrkJ8GHHnqIunXrcvfddxfZJ39V8mrFlxEnTpxY5nluvvnmygcbZ8oscYtIA6A38BqA\nqh4OrBpiIuSpp2D/fqhfH5Yt8zoaY8pn/fr1pKWlcfXVV5Oens6WLVsYNWoUfr+f9PR0Hn744fx9\ngyXgvLw8GjZsyJgxY+jSpQvnnHMO27dvB+D+++/nqaeeyt9/zJgxdO/enfbt2/Pxxx8DsH//fi6/\n/HLS0tIYPnw4fr8/5JJ1bm4uv/jFL+jcuTOZmZl8+OGHAKxatYqzzjqLrl27kpGRwYYNG9i7dy8D\nBw6kS5cudOrUienTQ1l4KfxCKXG3wc2tPFFEugDLgNtVdX/hnURkFDAKoHXrstZtNSX58Ud45hm4\n7DJQdSVuY8r0619DuKsAunZ1pYgKWLNmDZMmTcLv9wPw2GOP0bhxY/Ly8ujbty/Dhw8nLS2tyHN2\n795Nnz59eOyxx7jzzjuZMGECY8aMOeHYqsqSJUt4++23efjhh5k3bx7PPvssJ598MjNmzGDFihVk\nZmaGHOszzzxDzZo1WbVqFatXr2bQoEGsW7eOF154gbvvvpuf/exnHDp0CFVl9uzZpKam8u677+bH\n7IVQ6rhrAJnAi6raDdgPnPBuqup4VfWrqr9Zs5AmuDLFeOYZ2LMH7r8ffD746it325hYcsYZZ+Qn\nbYCpU6eSmZlJZmYmWVlZfPnllyc8p1atWgwcOBAAn8/Hxo0biz32ZZdddsI+ixYtYsSIEQB06dKF\n9PT0kGNdtGgR11xzDQDp6em0aNGC9evXc+655zJ27Fgef/xxvv/+e1JSUsjIyGDevHmMGTOGjz76\niAYNGoR8nnAKpcSdDWSranCh0+kUk7hN5e3Z4wo4gwdDt26wbZu7f/lyOP98T0Mz0a6CJeNIqVOn\nTv72unXrePrpp1myZAkNGzbkmmuuKbYfc3Jycv529erVycvLK/bYNWvWLHOfcLj22ms555xzmDNn\nDgMGDGDChAn07t2bpUuXMnfuXMaMGcPAgQO57777IhZDScoscavqVuB7EWkfuKsfcOLXpam0F16A\nXbvggQfcbZ/PXVs9t4lle/bsoV69etSvX58tW7bw3nvvhf0cPXv25M033wRc3XRxJfqS9OrVK7/X\nSlZWFlu2bKFt27Zs2LCBtm3bcvvttzN48GBWrlzJpk2bqFu3Ltdeey133XUXy5cvD/trCUWovUpu\nBSYHepRsAK6PXEiJaf9++Mtf4OKLoXt3d1+zZtC6tdVzm9iWmZlJWloaHTp04LTTTqNnz55hP8et\nt97Kz3/+c9LS0vIvJVVjXHzxxfnzhPTq1YsJEyZw00030blzZ5KSkpg0aRLJyclMmTKFqVOnkpSU\nRIsWLXjooYf4+OOPGTNmDNWqVSM5OZmXXnop7K8lFBFZc9Lv96stpFA+48bBXXe5ftuF/64vvxxW\nrXJ13cYUlpWVRceOHb0OIyrk5eWRl5dHSkoK69at46KLLmLdunXUqBGd0zEV99mJyDJV9ZfwlCKi\n81UlmNxc+POfoW/fokkbXHXJzJmwezd41A5iTNTbt28f/fr1Iy8vD1Xl5ZdfjtqkHQ7x+8piyGuv\nwdatMGXKiY8FG+aXL3eJ3RhzooYNG7IsgRqDbK4Sjx06BH/6kytpF9dzJNhAaTVPxpggK3F77G9/\ng+xsePVVKG7SsCZNIDXVepYYYwpYidtDR47AH/8IZ50FF11U8n4+n5W4jTEFLHF7aPJk2LjR9dsu\nbYpevx++/tr18TbGGEvcHjl6FP7wBzcdxODBpe8brOf2qK+/McXq27fvCYNpnnrqKUaPHl3q8+rW\nrQvA5s2bGT58eLH7nH/++ZTVpfipp57iwIED+bcHDRrEjz9Wfv67hx56iCeeeKLSx4kkS9wemTYN\n1q1zc5KUtSCGjaA00ejKK6/kjTfeKHLfG2+8wZVXXhnS81u0aFGp2fWOT9xz586lYcOGFT5eLLHE\n7YFjx9xCCenpMGxY2fs3bgxt2lg9t4kuw4cPZ86cOfmLJmzcuJHNmzfTq1ev/H7VmZmZdO7cmdmz\nZ5/w/I0bN9KpUyfATa06YsQIOnbsyLBhw8jNzc3fb/To0flTwj744IOAm9Fv8+bN9O3bl76BfrKp\nqans3LkTgHHjxtGpUyc6deqUPyXsxo0b6dixIzfeeCPp6elcdNFFRc5TluKOuX//fi655JL8aV6n\nTZsGwJgxY0hLSyMjI+OEOcrDwXqVeGDGDMjKcv22S5hf/gR+v5W4Tcm8mNW1cePGdO/enXfffZeh\nQ4fyxhtvcMUVVyAipKSkMGvWLOrXr8/OnTvp0aMHQ4YMKXG9xRdffJHatWuTlZXFypUri0zL+uij\nj9K4cWOOHj1Kv379WLlyJbfddhvjxo1jwYIFNG3atMixli1bxsSJE1m8eDGqytlnn02fPn1o1KgR\n69atY+rUqbzyyitcccUVzJgxI39mwNKUdMwNGzbQokUL5syZA7hpXnNycpg1axZr1qxBRMJSfXM8\nK3FXsWBpu107uOKK0J/n88GGDfDDD5GLzZjyKlxdUriaRFW57777yMjIoH///mzatIltwekui/Hh\nhx/mJ9CMjAwyMjLyH3vzzTfJzMykW7durF69uswJpBYtWsSwYcOoU6cOdevW5bLLLmPhwoUAtGnT\nhq5duwKlTx0b6jE7d+7M+++/z7333svChQtp0KABDRo0ICUlhV/+8pfMnDmT2rXDv2CYlbir2D/+\nAStXuv7b1auH/rzCIyj7949MbCZ2eTWr69ChQ7njjjtYvnw5Bw4cwBdokJk8eTI7duxg2bJlJCUl\nkZqaWuxUrmX55ptveOKJJ/j0009p1KgR1113XYWOExScEhbctLDlqSopTrt27Vi+fDlz587l/vvv\np1+/fvzv//4vS5Ys4d///jfTp0/nueeeY/78+ZU6z/GsxF2FVOGRR+D00+Gqq8r33OAvR6vnNtGk\nbt269O3blxtuuKFIo+Tu3btp3rw5SUlJLFiwgG+//bbU4/Tu3ZspgTkfvvjiC1auXAm4KWHr1KlD\ngwYN2LZtW/7KMwD16tVj7969JxyrV69evPXWWxw4cID9+/cza9YsevXqVanXWdIxN2/eTO3atbnm\nmmu45557WL58Ofv27WP37t0MGjSIJ598khUrVlTq3MWxEncVmjfP1VO/8gqUd/6bRo3gjDOsnttE\nnyuvvJJhw4YV6WFy9dVXc+mll9K5c2f8fj8dOnQo9RijR4/m+uuvp2PHjnTs2DG/5N6lSxe6detG\nhw4dOPXUU4tMCTtq1CgGDBhAixYtWLBgQf79mZmZXHfddXQPzI88cuRIunXrFnK1CMDYsWPzGyAB\nsrOziz3me++9xz333EO1atVISkrixRdfZO/evQwdOpSDBw+iqowbNy7k84bKpnWtIqpuPpJNm1w3\nwEKLfYTsZz+DJUvgm2/CH5+JPTata+yq7LSuVlVSRebPh08+gXvvrVjSBlfPvXEj5OSENTRjTIyx\nxF1FHnkETjkFbrih4sewgTjGGLDEXSUWLoQPPoDf/AZSUip+nGADpSVuExSJqk4TWeH4zCxxV4FH\nHoHmzWHUqModp2FDaNvWepYYJyUlhZycHEveMURVycnJIaUyJTisV0nELV4M77/vFksIRz98v9/V\nlRvTqlUrsrOz2bFjh9ehmHJISUmhVatWlTqGJe4Ie+QRN9dIGROmhczngzfegJ074biRvibBJCUl\n0aZNG6/DMB6wqpIIWr4c5syBO+6AevXCc0xroDTGWOKOoEcecSuz33pr+I5pIyiNMZa4I2TlSnjr\nLbj9dpe8w6VBAzjzTCtxG5PIQqrjFpGNwF7gKJAX6uieRPboo1C3rkvc4eb3w0cfhf+4xpjYUJ4S\nd19V7WpJu2xZWfD3v8Mtt7iGyXDz+eC778A6ExiTmKyqJAL+8AeoVQvuvDMyxw9O8WrVJcYkplAT\ntwL/FJFlIlLsMBIRGSUiS0VkaSL3K12/3q1s8z//A82aReYc3bq5a2ugNCYxhZq4z1PVTGAgcLOI\n9D5+B1Udr6p+VfU3i1TGigF//CMkJUEElpnLV78+tG9vJW5jElVIiVtVNwWutwOzgO6RDCpWbdwI\nkybBjTe6CaUiyeezErcxiarMxC0idUSkXnAbuAj4ItKBxaI//QlE3GRSkeb3Q3Y2lLKMnzEmToVS\n4j4JWCQiK4AlwBxVnRfZsGLPpk0wYQJcfz2cemrkz2cjKI1JXGX241bVDUCXKoglpj3+OBw9CmPG\nVM35unVzpftly2DQoKo5pzEmOlh3wDDYuhXGj4drr4WqmvOnXj3XQGn13MYkHkvcYfCXv8Dhw3Df\nfVV7Xr/fqkqMSUSWuCtpxw544QUYMcLNIVKVfD5Xt751a9We1xjjLUvclfTkk5CbC7/7XdWf20ZQ\nGpOYLHFXwg8/wHPPwfDhkJZW9efv2tU1UFo9tzGJxRJ3JTzzDOzdC/ff783569aFjh2txG1MorHE\nXUF79sDTT8PQoZCR4V0cNoLSmMRjibuCnnsOfvwRHnjA2zj8ftiyBTZv9jYOY0zVscRdAfv2wbhx\nMHBgwQhGr9gISmMSjyXuCnjpJcjJ8b60Da6Bslo1S9zGJBJL3OWUmwtPPAH9+sE553gdDdSp4xoo\nrZ7bmMQR0pqTpsArr7gZ+aZN8zqSAn4/vPceqLrugcaY+GYl7nI4dMhNJtWrF/Tp43U0BXw+N3rS\nGiiNSQxW4i6HiRPdEPOJE72OpKjCIyhbtvQ2FmNM5FmJO0RHjsBjj8HZZ0P//l5HU1SXLq6B0uq5\njUkMVuIO0f/9H3z7LTz/fPTVI9eu7YbcW88SYxKDlbhDkJcHjz4KmZnRu2iB3+9K3KpeR2KMiTRL\n3CGYOhU2bHD9tqOttB3k88H27a4O3hgT36Iqcb/1Fnz5ZXSVGo8edaXtzp1hyBCvoylZsIHS6rmN\niX9RU8d96JBbjODQIWjSBHr2dN3uevVyVRRJSd7ENX06rF3r+m1Xi6qvuaK6dIHq1V09909+4nU0\nxphIiprEnZwMq1bBwoWwaJG7fvtt91itWtCjR0Ei79HDTWkaaceOwdix0KEDXH555M9XGbVqQXq6\nlbiNSQRRk7hF3NJfZ54JN9zg7tuyBT76yCXxhQtdEj12zJUsu3VzSfy889ylefPwxzR7NnzxhetR\nUr16+I8fbj4fvPOOjaA0Jt6JRqBC2e/369IIFP327IFPPilI5IsXu6oVcCueBxN5r15utfXKJC9V\nlwj37IE1a6BG1HzFleyFF+Dmm123xdatvY7GGFMeIrJMVf2h7BsD6ahA/fpw8cXuAi5pL1tWUL0y\nfTq8+qp7rEWLgiTeqxd06lS+UvPcufDZZ/Daa7GRtKHoFK+WuI2JXyGXuEWkOrAU2KSqg0vbN1Il\n7rIcOwarVxetJ8/Odo81aADnnluQyM86C2rWLP44qm7mv61bYd067xpGyys313253Xuvq1YyxsSO\nSJW4bweygPoViqoKVKvmuu117gy/+pVLwN9+W5DEFy6Ed991+9as6ZJ3MJGfe65L7gD/+perhnnx\nxdhJ2mANlMYkipBK3CLSCvgb8ChwZ7SWuEOxc2fRBs/ly93ISBG3dmSvXu7x7dvh669LLpVHq5Ej\nXaPq9u3WQGlMLIlEifsp4DdAvVJOOgoYBdA6iitYmzZ1C/wOHepu79/vStfB6pWJE919zz0Xe0kb\nXD33a6/Bd9/Baad5HY0xJhLKTNwiMhjYrqrLROT8kvZT1fHAeHAl7rBFGGF16sAFF7gLuFkAN2yA\ndu28jauiCk/xaonbmPgUyljAnsAQEdkIvAFcICKvRzQqDyUlua6FsVrN0Lmz6wUTpTVVxpgwKDNx\nq+pvVbWVqqYCI4D5qnpNxCMzFZKS4pK3TfFqTPyK4tk3TEX5fDbFqzHxrFyJW1X/U1aPEuM9vx9+\n+MF1hTTGxB8rcceh4AhKq+c2Jj5Z4o5DnTu7Rlar5zYmPlnijkM1a7rkbSVuY+KTJe445fe7Erc1\nUBoTfyxxxymfD3btgm++8ToSY0y4WeKOU4VHUBpj4osl7jjVqZNbDs7quY2JP5a441Ryso2gNCZe\nWeKOY9ZAaUx8ssQdx3w++PFHN9uhMSZ+WOKOY8EGSqvnNia+WOKOY+nprq7b6rmNiS+WuONYcjJ0\n6WIlbmPijSXuOOfzuXU1jx3zOhJjTLhY4o5zfj/s3u0WPjbGxAdL3HEuOMWr1XMbEz8scce59HQ3\nW6DVcxsTPyxxx7mkJNdAaSVuY+KHJe4EEBxBaQ2UxsQHS9wJwOeDvXth/XqvIzHGhIMl7gRgIyiN\niS+WuBNAWhqkpFg9tzHxwhJ3AqhRA7p2tRK3MfHCEneCsBGUxsSPMhO3iKSIyBIRWSEiq0Xk91UR\nmAkvvx/27YOvvvI6EmNMZYVS4j4EXKCqXYCuwAAR6RHZsEy42QhKY+JHmYlbnX2Bm0mBi62pEmM6\ndoRatSxxGxMPQqrjFpHqIvI5sB14X1UXF7PPKBFZKiJLd+zYEe44TSVZA6Ux8SOkxK2qR1W1K9AK\n6C4inYrZZ7yq+lXV36xZs3DHacLA74fPPoOjR72OxBhTGeXqVaKqPwILgAGRCcdEks9nDZTGxINQ\nepU0E5GGge1awIXAmkgHZsIvOILS6rmNiW2hlLhPARaIyErgU1wd9zuRDctEQocOULu21XMbE+tq\nlLWDqq4EulVBLCbCqleHbt2sxG1MrLORkwkmOILSGiiNiV2WuBOMzwcHDsDatV5HYoypKEvcCcam\neDUm9lniTjDt20OdOlbPbUwss8SdYIINlFbiNiZ2WeJOQD4ffP455OV5HYkxpiIscScgv981UK6x\nYVTGxKToStyHD3sdQUKwKV6NiW3Rk7h374Zzz4Unn/Q6krjXrh3UrWv13MbEquhJ3HXqwOmnw513\nwrPPeh1NXLMRlMbEtjKHvFeZGjVg8mQ3pO+221x2+dWvvI4qbvn98NJLroGyRvT8FRhjQhA9JW6A\npCSYOhWGDIGbb4bx472OKG75fJCbC1lZXkdijCmv6ErcAMnJ8OabMGgQ3HQTTJjgdURxyUZQGhO7\noi9xA9SsCTNmwMUXw8iRMGmS1xHFnTPPhHr1rJ7bmFgUnYkbICUFZs2Cfv3g+uthyhSvI4or1apB\nZqaVuI2JRdGbuMEtSz57NvTuDddeC9OmeR1RXPH5YMUKOHLE60iMMeUR3Ykb3JIt77wDPXvC1Ve7\nKhQTFn4/HDwIX37pdSTGmPKI/sQNro/3nDlw9tkwYoQrhZtKsxGUxsSm2Ejc4FrS3n3XZZuf/tSV\nwk2ltG0L9etbPbcxsSZ2Eje4LPPee9ClC1x+Ocyb53VEMS3YQGklbmNiS2wlboAGDeCf/4T0dPjJ\nT+D9972OKKb5/dZAaUysib3EDdCokUvYHTq4UZbz53sdUczy+eDQIVi92utIjDGhis3EDdCkiUve\nbdvCpZfCBx94HVFMshGUxsSe2E3cAM2awb//DampcMklsGiR1xHFnDPOcLVPVs9tTOwoM3GLyKki\nskBEvhSR1SJye1UEFrLmzV3ybtUKBg6ETz7xOqKYIuKqS6zEbUzsCKXEnQfcpappQA/gZhFJi2xY\n5XTyya6e+5RTYMAAWLLE64hiis8HK1faAkTGxIoyE7eqblHV5YHtvUAW0DLSgZVbixYueTdt6ian\nst/+IfP5XNK2BkpjYkO56rhFJBXoBiwu5rFRIrJURJbu2LEjPNGVV6tWsGABNGwIF17oljI3ZbIG\nSmNiS8iJW0TqAjOAX6vqnuMfV9XxqupXVX+zZs3CGWP5tG7tknfdutC/P6xa5V0sMeL00913nf1I\nMSY2hJS4RSQJl7Qnq+rMyIYUBqmpLnmnpLhpYa0OoFTWQGlMbAmlV4kArwFZqjou8iGFyRlnuORd\no4ZL3mvWeB1RVAs2UB465HUkxpiyhFLi7glcC1wgIp8HLoMiHFd4nHlmwajKCy6Ar77yNp4o5ve7\nYe9ffOF1JMaYsoTSq2SRqoqqZqhq18BlblUEFxYdOrjknZcHffvC+vVeRxSVbIpXY2JHbI+cDFVa\nmkvehw65kvc333gdUdRp08ZNAWP13MZEv8RI3ACdOrkRlvv3u5L3t996HVFUCTZQWonbmIrZtavq\nVpNKnMQNbh7v99+H3btd8v7+e68jiip+v+s9aQ2UxpTP4cNuiYDzz4d9+yJ/vsRK3OBWDvjnPyEn\nx1WbbNrkdURRw+dzDZTW9d2Y0KnCjTe6TmzjxrkhJJGWeIkb4Kyz3Eo627a55L1li9cRRQUbQWlM\n+T3yCEyaBL//PVxzTdWcMzGH3E9zAAAPUElEQVQTN0CPHm4Ny02bXD/vbdu8jshzp50GjRtbPbcx\noXr9dXjwQfjFL+CBB6ruvImbuAF69oS5c11DZb9+4NUcK1FCxJW6rcRtTNk++ABuuME1l40f7/5/\nqkpiJ26A3r3divEbNri5TXJyvI7IUz6fG4Rz8KDXkRgTvdauhWHD3ADtGTMgOblqz2+JG9xX5ttv\nu5GV/fvDDz94HZFn/H43VmnlSq8jMSY6bd8OgwZBUpL7wd6oUdXHYIk7qH9/eOst1xHzoosStuRt\nIyiNKVluLgwdCps3u7JemzbexGGJu7CLL4aZM11/uIwMN2AnwbRu7daisHpuY4o6dgyuvRYWL4bJ\nk+Hss72LxRL38S65BP77X6hf35XC77knoUak2AhKY4o3Zoyrz/7zn+Gyy7yNxRJ3cbp1c5lr9Gh4\n4gnXdTAry+uoqozf7xooc3O9jsSY6PDyyy5hjx4Nd97pdTSWuEtWuza88ALMng3Z2a4Y+tJLbphU\nnPP54OhRa6A0BmDePLj5Ztcg+cwzVdvtrySWuMsyZIjLYL16ua/boUPjvr+3jaA0xlmxAn76U+jc\nGaZNc+uyRANL3KE45RQ3yvKpp9xQ+YwMdx2nWrWCZs2sntsktk2bXJNXgwZuqEdVzEESKkvcoapW\nDW6/HT79FJo0gQED4I474nKkio2gNIlu714YPNhNJDpnDrRs6XVERVniLq+MDJe8b73VlcC7d4/L\n9b58Ptel/cABryMxpmrl5cGIEa5X8N//7maDjjaWuCuiVi3XSjFnjpucyu+HZ5+Nq4ZLv981UK5Y\n4XUkxlQdVffDeu5ceP5598M6GlniroxBg1zDZb9+cNttrkIsTmYZtBGUJhE9+aTrTHbPPXDTTV5H\nUzJL3JV10kmu5eK559xM6p07u5J4jGvZEpo3t3pukzhmzoS774bhw+Gxx7yOpnSWuMNBxHX0XLrU\n9UAZPBhuuSWmR7AEGyitxG0SweLFcPXVbhj7pEmuL0I0i/LwYkx6uvsLuOMOV0Hm98d0JXGwgXL/\nfq8jMSZyvvkGLr3Ulblmz3ZNWNHOEne4paS4hefee89ND9u9u6s4O3bM68jKze93Ycfwd48xpdq1\nyzVV5eW5Bsnmzb2OKDRlJm4RmSAi20Uk/vq8RdJFF7n+RAMGuMkNBg6MubUtgw2UVs9t4lFwZfav\nv4ZZs6BDB68jCl0oJe6/AlHaKSbKNW3q5vh+6SVYuNA1XM6e7XVUIWvRAk4+2eq5TfwpvDL7hAnQ\np4/XEZVPmSPvVfVDEUmNfChxSsT1K+rTB666Cn7yE3d73Dg3kVUUC07xunChG4iQlOTmaqjsdfXq\n0TFRj0lcXqzMHk5RMmVKAujQwc3z/cADbn7I//wHpkyBzEyvIytV796ud+MVV4T3uCUl9tKSflKS\na0KoWdNdIrWdnGxfLPHMq5XZw0k0hNF+gRL3O6raqZR9RgGjAFq3bu379ttvwxRiHJo/H37+c7d4\n3aOPwl13RW3/o2PHXB3g4cNw5Ii75OWF57q8zzl82K1pcfCguy5uO1xtwMnJxSf3lBT34+m++9yU\nNSa2fPABXHghnHeem661qhf5LY2ILFNVf0j7hitxF+b3+3WptWiVLifHVZnMmAEXXAB/+5ubls9U\nSl5e6cm9rMRf1vbu3e57t149l7xvu80lcxP91q6Fc85xY+Y+/tibRX5LY4k7VqjCxInuvz85GV55\nxTVzm6j2xRduGas5c9wanWPHusEbUfqjyeCm0O/RA/btczWWXi3yW5ryJO5QugNOBT4B2otItoj8\nsrIBmgARuOEG+OwzaNvWjbUdOdL9dZmo1amTm+Vg/nzXcejnP3eNuP/6l9eRmeLk5rr1ULxemT2c\nykzcqnqlqp6iqkmq2kpVX6uKwBLKmWfCRx+5394TJrgGy08/9ToqU4a+fd3HNHmyG8hx4YWuu74t\n+RY9jh1zX6zRsDJ7ONmPu2iRlOQaKhcscJWq557rfoP/8IPXkZlSVKvmenmuWePWlf7vf6FrV/dD\nKjvb6+jMb38L06e7z8brldnDyRJ3tOnTx40xv/xy11epeXPo39/NfbJpk9fRmRKkpLjOQV9/7QbK\nTp4M7drB737nGjRN1Xv5ZXj8cfjVr9z0QfEkpMbJ8rLGyTBQheXL3VyTM2e6Ih2433rDhrlLu3be\nxmhKtHGjS9pTprh68AcfhFGjoqv7WTybN89N0nnxxW6wcrQs8luasPcqKS9L3BGwZo2bUGHWrIL6\n77Q09/tv2DDo1s1GjUShZcvcpPwLFrj258cecx+ZfVSRs2KF66fdtq0b9RtNi/yWxhJ3vPv+ezcH\nyqxZ8OGHbo2x005zw+kvuwx69nTjyk1UUHUzz/3mN26a3HPOcYNne/b0OrL4s2lTQQPk4sXRt8hv\nacLaHdBEoVNPdYsVz58PW7e6nigZGW4yqz593MTCI0e6jsaHDnkdbcITcavarVgBr77qqlHOO899\nx371ldfRxY9oX5k9nCxxx7qmTeH6610H1Z074c03XWPm3//u/oqbNnVLVk+b5v6yjWdq1IBf/hLW\nrYOHH4b333e1XTff7GY/MBUXCyuzh5NVlcSrQ4dcxerMma51Zvt21zJ24YWuTnzIEGjWzOsoE9q2\nbS6Bv/yyW3Xl3ntdj5QonzQy6qi6lQJfeMH96IzmRX5LY3XcpqijR+GTT1yd+MyZ7rd6tWru93qw\nh8ppp3kdZcJau9YNoX/rLTcH+sMPw3XXWTNFcXbsgKysEy/ff+/aEP70J68jrDhL3KZkqq6yNdhD\nZdUqd39mpkvgl10GHTtatwcPLFrkeqD8979u+dLHH3cjMRPto1B1ifj45Pzll25utqDatd2faseO\nbh6S0aNje74YS9wmdOvXFyTxTz5x97VrV1ASP+us2P5viDGqbsLIMWPcYJ4LLnAJPLiMXDzJy3Ov\n8fgEvWZN0el6Gjd2yTktrSBRd+zo2ujj6U/TErepmM2bXX34rFmufjwvzzXNDxzoeq2kp7v/npNO\nSrxiYBU7fNjVff/+966UedVVbkaE1FSvIyu/3FxXHXR8gl63zr3OoJYtC5Jy4STdrFli/LlZ4jaV\nt2uXmwJv1iy3Ws+uXQWPNW5ckMQLX1tCD7vdu1297ZNPugmTbrvNzUUWbXNJg4s1WKVROEF/8437\nJQGuhHz66Scm6A4doH59b+P3miVuE16qrgvE6tXu8uWXBdvHJ/Tjk7kl9LDIznZT1/ztb9CwoUve\nZ5/t2p2PHXPXhbePvy7tsco8PzfXlZyzsmDLloJ4k5OhffuiVRtpaW4iTFt4oniWuE3VKJzQCyfz\n4xN6o0YnJvO0NLeEvCX0clmxwnUbfO+9qj2viCstV6/uLsHtpCQ444yiCbpjRzfndSzMDxJNLHEb\nbwUTeuFkHtwuPE1to0YnJvP0dEvoIfjsM/dWFk6ix1+X9lh597WPI/IscZvopOoGAhVX5VJSQi98\nfcoplkFM3CpP4rYfM6bqiLj67pNOcv3cggon9MLJfPr0ogm9Zk23tHrjxgXXoWzXqlX1r9WYCLLE\nbbxXVkIPJvPvvnOJ/IcfXB+5desKtkubTCslpXyJPrhtrWgmSlniNtGrcELv27fk/VRd94ZgEi+c\n3IvbXru24L7CHYmPV6tW8Qm9fn2oU8dN9FynTsnbhe+zljoTRvbXZGKfiBv/XLs2tGoV+vNU4cCB\n4pN7cYl/7Vp3vXcv7N9fvhhr1gwtwZfn8dq13ZdLPA0fNCGxxG0Sl0hBEjz11PI9N9iJef9+Nz67\n8HVZ9xXe3rLlxPuOHClfLMnJLoEHL8GEXp5LeZ5jvx48Z5+AMRVRrVpB0m/ePLzHPny49GQf3M7N\ndb8YcnNLvuzZ4xbbKO6xivYoq1GjaKJPSnL31ahR/HZVPV69+onXxd0XymPB6yj9NWOJ25hok5zs\nLpEc167qviAKJ/KyvgRK2icvz12OHCl6nZfnHt+7t+THi9s+cqTiXyqRUFZyL7zdvLlb6DLSIUX8\nDMaY6CPi6t1r1nRj6KPNsWOlJ/bi7guOzc/LK3pd3H2R2qdevSp5e0JK3CIyAHgaqA68qqqPRTQq\nY0xiq1at4JeHOUGZFTgiUh14HhgIpAFXikhapAMzxhhTvFBq3rsD61V1g6oeBt4AhkY2LGOMMSUJ\nJXG3BL4vdDs7cF8RIjJKRJaKyNIdO3aEKz5jjDHHCVtfF1Udr6p+VfU3s9XDjTEmYkJJ3JuAwqMT\nWgXuM8YY44FQEvenwJki0kZEkoERwNuRDcsYY0xJyuwOqKp5InIL8B6uO+AEVV0d8ciMMcYUK6R+\n3Ko6F5gb4ViMMcaEICIr4IjIDuDbCj69KbAzjOHEMnsvirL3oyh7PwrEw3txmqqG1LMjIom7MkRk\naajL98Q7ey+KsvejKHs/CiTaexGdU18ZY4wpkSVuY4yJMdGYuMd7HUAUsfeiKHs/irL3o0BCvRdR\nV8dtjDGmdNFY4jbGGFMKS9zGGBNjoiZxi8gAEVkrIutFZIzX8XhJRE4VkQUi8qWIrBaR272OyWsi\nUl1EPhORd7yOxWsi0lBEpovIGhHJEpFzvI7JSyJyR+D/5AsRmSoiKV7HFGlRkbhtsYYT5AF3qWoa\n0AO4OcHfD4DbgSyvg4gSTwPzVLUD0IUEfl9EpCVwG+BX1U64aTlGeBtV5EVF4sYWayhCVbeo6vLA\n9l7cP+YJc6AnChFpBVwCvOp1LF4TkQZAb+A1AFU9rKo/ehuV52oAtUSkBlAb2OxxPBEXLYk7pMUa\nEpGIpALdgMXeRuKpp4DfAMe8DiQKtAF2ABMDVUevikgdr4PyiqpuAp4AvgO2ALtV9Z/eRhV50ZK4\nTTFEpC4wA/i1qu7xOh4viMhgYLuqLvM6lihRA8gEXlTVbsB+IGHbhESkEe7XeRugBVBHRK7xNqrI\ni5bEbYs1HEdEknBJe7KqzvQ6Hg/1BIaIyEZcFdoFIvK6tyF5KhvIVtXgL7DpuESeqPoD36jqDlU9\nAswEzvU4poiLlsRtizUUIiKCq8PMUtVxXsfjJVX9raq2UtVU3N/FfFWN+xJVSVR1K/C9iLQP3NUP\n+NLDkLz2HdBDRGoH/m/6kQCNtSHNxx1ptljDCXoC1wKrROTzwH33BeZFN+ZWYHKgkLMBuN7jeDyj\nqotFZDqwHNcb6zMSYPi7DXk3xpgYEy1VJcYYY0JkidsYY2KMJW5jjIkxlriNMSbGWOI2xpgYY4nb\nGGNijCVuY4yJMf8P1sfouKyJ5vwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oS3duzLt3Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjVIlMRgx4eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}